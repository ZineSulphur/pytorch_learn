{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## [torch.nn](https://pytorch.org/docs/stable/nn.html)\n",
    "nn是神经网络Neural Network的简写，这个库里集成了pytorch的神经网络相关的算法和模型。\n",
    "***\n",
    "### Containers\n",
    "Containers是pytorch中的神经网络模型的容器。\n",
    "|类|简介|\n",
    "|---|---|\n",
    "|Module|所有神经网络模块的基类|\n",
    "|Sequential|顺序存储容器|\n",
    "|ModuleList|子模块列表|\n",
    "|ModuleDict|子模块字典|\n",
    "|ParameterList|参数列表|\n",
    "|ParameterDict|参数字典|\n",
    "\n",
    "其中Module类最常使用。\n",
    "#### [Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module)\n",
    "Module是所有神经网络模块的基类，我们的模型都需要继承它，并且重写其中的__init__和forward等方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = input + 1\n",
    "        return output\n",
    "\n",
    "md = MyModule()\n",
    "x = torch.tensor(1.)\n",
    "y = md.forward(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Layers 卷积层\n",
    "Convolution Layers为torch中提供的卷积层模型。\n",
    "|类|简介|\n",
    "|---|---|\n",
    "|nn.Conv1d|对输入进行一维卷积|\n",
    "|nn.Conv2d|对输入进行二维卷积|\n",
    "|nn.Conv3d|对输入进行三维卷积|\n",
    "|nn.ConvTranspose1d|一维转置卷积|\n",
    "|nn.ConvTranspose2d|二维转置卷积|\n",
    "|nn.ConvTranspose3d|三维转置卷积|\n",
    "|nn.LazyConv1d|省略输入参数的Conv1d|\n",
    "|nn.LazyConv2d|省略输入参数的Conv2d|\n",
    "|nn.LazyConv3d|省略输入参数的Conv3d|\n",
    "|nn.LazyConvTranspose1d|省略in_channel的ConvTranspose1d|\n",
    "|nn.LazyConvTranspose2d|省略in_channel的ConvTranspose2d|\n",
    "|nn.LazyConvTranspose3d|省略in_channel的ConvTranspose3d|\n",
    "|nn.Unfold|滑动窗口提取|\n",
    "|nn.Fold|逆滑动窗口提取|\n",
    "\n",
    "其中nn.Conv2d常用于图像识别中。\n",
    "```python\n",
    "torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "torch.nn.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "torch.nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "torch.nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)\n",
    "```\n",
    "**Parameters**\n",
    "* in_channels   - 输入通道数\n",
    "* out_channels  - 卷积产生的通道数\n",
    "* kernel_size   - 卷积核大小，int或者tuple\n",
    "* stride        - 卷积步长，可选int或者tuple\n",
    "* padding       - 填充数目，可选int或者tuple\n",
    "* padding_mode  - 填充模式，可选'zeros', 'reflect', 'replicate' or 'circular'\n",
    "* dilation      - 卷积核点间隔，可选int或者tuple\n",
    "* groups        - 控制分组卷积\n",
    "* bias          - 控制是否有偏差参数，bool\n",
    "\n",
    "#### [卷积层参数演示动画](https://github.com/vdumoulin/conv_arithmetic)\n",
    "#### [卷积原理讲解推荐](https://www.bilibili.com/video/BV1Vd4y1e7pj/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(\"./data\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=64)\n",
    "\n",
    "class MyConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "\n",
    "myConv = MyConv()\n",
    "writer = SummaryWriter(\"./logs\")\n",
    "step = 0\n",
    "for data in dataloader:\n",
    "    img, target = data\n",
    "    output = myConv(img)\n",
    "    if(step == 0):\n",
    "        print(img.shape)\n",
    "        print(output.shape)\n",
    "    writer.add_images(\"conv_input\", img, step)\n",
    "    writer.add_images(\"conv_output\", output, step)\n",
    "    step += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Pooling layers 池化层\n",
    "|类|简介|\n",
    "|---|---|\n",
    "|nn.MaxPool1d|一维最大池化|\n",
    "|nn.MaxPool2d|二维最大池化|\n",
    "|nn.MaxPool3d|三维最大池化|\n",
    "|nn.MaxUnpool1d|一维反最大池化|\n",
    "|nn.MaxUnpool2d|二维反最大池化|\n",
    "|nn.MaxUnpool3d|三维反最大池化|\n",
    "|nn.AvgPool1d|一维平均池化|\n",
    "|nn.AvgPool2d|二维平均池化|\n",
    "|nn.AvgPool3d|三维平均池化|\n",
    "|nn.FractionalMaxPool1d|一维分数最大池化|\n",
    "|nn.FractionalMaxPool2d|二维分数最大池化|\n",
    "|nn.FractionalMaxPool3d|三维分数最大池化|\n",
    "|nn.LPPool1d|一维LP池化|\n",
    "|nn.LPPool2d|二维LP池化|\n",
    "|nn.LPPool3d|三维LP池化|\n",
    "|nn.AdaptiveMaxPool1d|一维自适应最大池化|\n",
    "|nn.AdaptiveMaxPool2d|二维自适应最大池化|\n",
    "|nn.AdaptiveMaxPool3d|三维自适应最大池化|\n",
    "|nn.AdaptiveAvgPool1d|一维自适应平均池化|\n",
    "|nn.AdaptiveAvgPool2d|二维自适应平均池化|\n",
    "|nn.AdaptiveAvgPool3d|三维自适应平均池化|\n",
    "\n",
    "#### 池化\n",
    "由于参与运算的张量太大时，会影响计算速度和计算结果，所以需要使用池化对张量进行采样，提取图像特征，减少运算量等。\n",
    "#### 池化特点\n",
    "* 池化层没有训练参数\n",
    "* 只改变特征矩阵的W和H，不改变channel（深度）（如果一个4 x 4 x3 （WHC）的矩阵，若经大小为2 x 2、且布距也为2 的池化核操作，最终会得到2 x 2 x 3 的矩阵结果）\n",
    "* 一般pool size（池化核大小）和 stride（步距）相同\n",
    "#### 池化作用\n",
    "* 下采样（downsamping），降维、去除冗余信息，同时增大了感受野，保留feature map的特征信息，降低参数量\n",
    "* 可以实现特征不变性（feature invariant）\n",
    "* 实现非线性，在一定程度上能防止过拟合的发生\n",
    "#### MaxPool 最大池化\n",
    "选定某一卷积核的区域，取这个区域中输入张量的最大值。\n",
    "|||||\n",
    "|---|---|---|---|\n",
    "|1|1|2|4|\n",
    "|5|6|7|8|\n",
    "|3|2|1|0|\n",
    "|1|2|3|4|\n",
    "\n",
    "-MaxPool->\n",
    "\n",
    "|||\n",
    "|---|---|\n",
    "|6|8|\n",
    "|3|4|\n",
    "\n",
    "```python\n",
    "torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "```\n",
    "**Parameters**\n",
    "* kernel_size   - 池化核大小\n",
    "* stride        - 池化步长\n",
    "* padding       - 填充数目\n",
    "* dilation      - 池化核点间隔\n",
    "* return_indices    - 为True时返回最大值点位置索引\n",
    "* ceil_mode     - 为Ture时用向上取整的方法计算输出形状，默认是向下取整\n",
    "#### AvgPool 平均池化\n",
    "选定某一卷积核的区域，取这个区域中输入张量的平均值。\n",
    "|||||\n",
    "|---|---|---|---|\n",
    "|1|1|2|4|\n",
    "|5|6|7|8|\n",
    "|3|2|1|0|\n",
    "|1|2|3|4|\n",
    "\n",
    "-AvgPool->\n",
    "\n",
    "|||\n",
    "|---|---|\n",
    "|3.25|5.25|\n",
    "|2|2|\n",
    "\n",
    "```python\n",
    "torch.nn.AvgPool2d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None)\n",
    "```\n",
    "**Parameters**\n",
    "* kernel_size   - 池化核大小\n",
    "* stride        - 池化步长\n",
    "* padding       - 填充数目\n",
    "* ceil_mode     - 为Ture时用向上取整的方法计算输出形状，默认是向下取整\n",
    "* count_include_pad - 为True时将把zero-padding的内容一起计算\n",
    "* divisor_override  - 指定时将使用该数字作为除数，否则为池化核大小\n",
    "#### 自适应池化\n",
    "AdaptivePooling，自适应池化层。函数通过输入原始尺寸和目标尺寸，自适应地计算核的大小和每次移动的步长。如告诉函数原来的矩阵是7x7的尺寸，我要得到3x1的尺寸，函数就会自己计算出核多大、该怎么运动。\n",
    "#### MaxUnpool 反池化\n",
    "通过接受Maxpool的结果和最大值索引，进行部分Maxpool的逆运算。\n",
    "```python\n",
    "torch.nn.MaxUnpool2d(kernel_size, stride=None, padding=0)\n",
    "```\n",
    "**Parameters**\n",
    "* kernel_size   - 池化核大小\n",
    "* stride        - 池化步长\n",
    "* padding       - 填充数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(\"./data\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=64)\n",
    "\n",
    "class MyPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyPool, self).__init__()\n",
    "        self.maxpoll1 = nn.MaxPool2d(kernel_size=3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.maxpoll1(x)\n",
    "        return y\n",
    "\n",
    "myPool = MyPool()\n",
    "writer = SummaryWriter(\"./logs\")\n",
    "step = 0\n",
    "for data in dataloader:\n",
    "    img, target = data\n",
    "    output = myPool(img)\n",
    "    if(step == 0):\n",
    "        print(img.shape)\n",
    "        print(output.shape)\n",
    "    writer.add_images(\"pool_input\", img, step)\n",
    "    writer.add_images(\"pool_output\", output, step)\n",
    "    step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
