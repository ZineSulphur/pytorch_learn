{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## [torch.nn](https://pytorch.org/docs/stable/nn.html)\n",
    "nn是神经网络Neural Network的简写，这个库里集成了pytorch的神经网络相关的算法和模型。\n",
    "***\n",
    "### Containers\n",
    "Containers是pytorch中的神经网络模型的容器。\n",
    "|类|简介|\n",
    "|---|---|\n",
    "|Module|所有神经网络模块的基类|\n",
    "|Sequential|顺序存储容器|\n",
    "|ModuleList|子模块列表|\n",
    "|ModuleDict|子模块字典|\n",
    "|ParameterList|参数列表|\n",
    "|ParameterDict|参数字典|\n",
    "\n",
    "其中Module类最常使用。\n",
    "#### [Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module)\n",
    "Module是所有神经网络模块的基类，我们的模型都需要继承它，并且重写其中的__init__和forward等方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = input + 1\n",
    "        return output\n",
    "\n",
    "md = MyModule()\n",
    "x = torch.tensor(1.)\n",
    "y = md.forward(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Layers 卷积层\n",
    "Convolution Layers为torch中提供的卷积层模型。\n",
    "|类|简介|\n",
    "|---|---|\n",
    "|nn.Conv2d|对输入进行一维卷积|\n",
    "|nn.Conv2d|对输入进行二维卷积|\n",
    "|nn.Conv3d|对输入进行三维卷积|\n",
    "|nn.ConvTranspose1d|一维转置卷积|\n",
    "|nn.ConvTranspose2d|二维转置卷积|\n",
    "|nn.ConvTranspose3d|三维转置卷积|\n",
    "|nn.LazyConv2d|省略输入参数的Conv1d|\n",
    "|nn.LazyConv2d|省略输入参数的Conv2d|\n",
    "|nn.LazyConv3d|省略输入参数的Conv3d|\n",
    "|nn.LazyConvTranspose1d|省略in_channel的ConvTranspose1d|\n",
    "|nn.LazyConvTranspose2d|省略in_channel的ConvTranspose2d|\n",
    "|nn.LazyConvTranspose3d|省略in_channel的ConvTranspose3d|\n",
    "|nn.Unfold|滑动窗口提取|\n",
    "|nn.Fold|逆滑动窗口提取|\n",
    "\n",
    "其中nn.Conv2d常用于图像识别中。\n",
    "```python\n",
    "torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "torch.nn.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "torch.nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "torch.nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)\n",
    "```\n",
    "**Parameters**\n",
    "* in_channels   - 输入通道数\n",
    "* out_channels  - 卷积产生的通道数\n",
    "* kernel_size   - 卷积核大小，int或者tuple\n",
    "* stride        - 卷积步长，可选int或者tuple\n",
    "* padding       - 填充数目，可选int或者tuple\n",
    "* padding_mode  - 填充模式，可选'zeros', 'reflect', 'replicate' or 'circular'\n",
    "* dilation      - 卷积核点间隔，可选int或者tuple\n",
    "* groups        - 控制分组卷积\n",
    "* bias          - 控制是否有偏差参数，bool\n",
    "\n",
    "#### [卷积层参数演示动画](https://github.com/vdumoulin/conv_arithmetic)\n",
    "#### [卷积原理讲解推荐](https://www.bilibili.com/video/BV1Vd4y1e7pj/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(\"./data\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=64)\n",
    "\n",
    "class MyConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "\n",
    "myConv = MyConv()\n",
    "writer = SummaryWriter(\"./logs\")\n",
    "step = 0\n",
    "for data in dataloader:\n",
    "    img, target = data\n",
    "    output = myConv(img)\n",
    "    if(step == 0):\n",
    "        print(img.shape)\n",
    "        print(output.shape)\n",
    "    writer.add_images(\"conv_input\", img, step)\n",
    "    writer.add_images(\"conv_output\", output, step)\n",
    "    step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3403, 0.0917, 0.2900, 0.6064, 0.0891, 0.6702, 0.0056, 0.4279]])\n",
      "tensor([[0.5049, 0.2209, 0.3136, 0.5080, 0.2250, 0.6419]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([[0.4106, 0.3210]], grad_fn=<SqueezeBackward1>)\n",
      "tensor([[0.3633, 0.6048, 0.6120, 0.2791, 0.7993, 0.1884, 0.7456, 0.2858]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([[-0.3567, -0.2794, -0.2921, -0.5562, -0.1746, -0.5497]],\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# 一维卷积\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "tensor1d = torch.rand(1,8)\n",
    "print(tensor1d)\n",
    "\n",
    "# 卷积\n",
    "conv1d1 = nn.Conv1d(1, 1, 3, 1, 0)\n",
    "output1 = conv1d1(tensor1d)\n",
    "print(output1)\n",
    "\n",
    "# stride = kernel_size\n",
    "conv1d2 = nn.Conv1d(1, 1, 3, stride=3)\n",
    "output2 = conv1d2(tensor1d)\n",
    "print(output2)\n",
    "\n",
    "# padding = 1\n",
    "conv1d3 = nn.Conv1d(1, 1, 3, padding=1)\n",
    "output3 = conv1d3(tensor1d)\n",
    "print(output3)\n",
    "\n",
    "# dilation = 1\n",
    "conv1d4 = nn.Conv1d(1, 1, 3, dilation=1)\n",
    "output4 = conv1d4(tensor1d)\n",
    "print(output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3317, 0.9029, 0.9095, 0.2939, 0.7692, 0.6878, 0.5697, 0.8918]])\n",
      "tensor([[-0.6762, -0.5518, -0.7697, -0.8440, -0.8553, -0.7672, -0.6713, -0.8288]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([[ 0.3114,  0.2088,  0.0365,  0.5302,  0.2508, -0.2182,  0.5327,  0.2513,\n",
      "         -0.2211,  0.2969,  0.2060,  0.0533,  0.4789,  0.2409, -0.1585,  0.4478,\n",
      "          0.2350, -0.1223,  0.4025,  0.2263, -0.0696,  0.5259,  0.2500, -0.2132]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([[0.4983, 0.5072, 0.1729, 0.4240, 0.3858, 0.3202, 0.4936, 0.0141]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([[ 0.2368,  0.0662, -0.0983, -0.1351, -0.1930, -0.0193, -0.1371, -0.1774,\n",
      "          0.0461,  0.0276]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# 一维反卷积\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "tensor1d = torch.rand(1,8)\n",
    "print(tensor1d)\n",
    "\n",
    "# 反卷积\n",
    "conv1d1 = nn.Conv1d(1, 1, 3, 1, 0)\n",
    "output1 = conv1d1(tensor1d)\n",
    "tconv1d1 = nn.ConvTranspose1d(1, 1, 3, 1, 0)\n",
    "toutput1 = tconv1d1(output1)\n",
    "print(toutput1)\n",
    "\n",
    "# stride = kernel_size\n",
    "tconv1d2 = nn.ConvTranspose1d(1, 1, 3, stride=3)\n",
    "toutput2 = tconv1d2(tensor1d)\n",
    "print(toutput2)\n",
    "\n",
    "# padding = 1\n",
    "tconv1d3 = nn.ConvTranspose1d(1, 1, 3, padding=1)\n",
    "toutput3 = tconv1d3(tensor1d)\n",
    "print(toutput3)\n",
    "\n",
    "# dilation = 1\n",
    "tconv1d4 = nn.ConvTranspose1d(1, 1, 3, dilation=1)\n",
    "toutput4 = tconv1d4(tensor1d)\n",
    "print(toutput4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7859, 0.9360, 0.2186, 0.2842, 0.1131],\n",
      "         [0.4350, 0.7167, 0.5941, 0.8981, 0.5835],\n",
      "         [0.2008, 0.2265, 0.1247, 0.1324, 0.0799],\n",
      "         [0.5277, 0.3427, 0.7648, 0.0844, 0.0153],\n",
      "         [0.5840, 0.1551, 0.1614, 0.1452, 0.0078]]])\n",
      "tensor([[[0.8765, 0.6541, 0.6316],\n",
      "         [0.6972, 0.9696, 0.7670],\n",
      "         [0.3622, 0.6087, 0.5412]]], grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.1707]]], grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2843, 0.1100, 0.1180, 0.1120, 0.1313],\n",
      "         [0.3477, 0.2675, 0.2236, 0.2460, 0.1628],\n",
      "         [0.2296, 0.2730, 0.1352, 0.2993, 0.2531],\n",
      "         [0.2022, 0.2501, 0.2319, 0.1570, 0.2512],\n",
      "         [0.3241, 0.2271, 0.2910, 0.2284, 0.2405]]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.3565, 0.2877, 0.2458],\n",
      "         [0.3553, 0.3446, 0.4393],\n",
      "         [0.3978, 0.1570, 0.0716]]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# 二维卷积\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "tensor2d = torch.rand(1,5,5)\n",
    "print(tensor2d)\n",
    "\n",
    "# 卷积\n",
    "conv2d1 = nn.Conv2d(1, 1, 3, 1, 0)\n",
    "output1 = conv2d1(tensor2d)\n",
    "print(output1)\n",
    "\n",
    "# stride = kernel_size\n",
    "conv2d2 = nn.Conv2d(1, 1, 3, stride=3)\n",
    "output2 = conv2d2(tensor2d)\n",
    "print(output2)\n",
    "\n",
    "# padding = 1\n",
    "conv2d3 = nn.Conv2d(1, 1, 3, padding=1)\n",
    "output3 = conv2d3(tensor2d)\n",
    "print(output3)\n",
    "\n",
    "# dilation = 1\n",
    "conv2d4 = nn.Conv2d(1, 1, 3, dilation=1)\n",
    "output4 = conv2d4(tensor2d)\n",
    "print(output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9701, 0.7000, 0.4823, 0.2108, 0.1587],\n",
      "         [0.3725, 0.6843, 0.1296, 0.0389, 0.0229],\n",
      "         [0.7798, 0.4541, 0.5359, 0.9609, 0.1035],\n",
      "         [0.3905, 0.2381, 0.9834, 0.1597, 0.8857],\n",
      "         [0.0396, 0.9173, 0.9949, 0.3432, 0.3522]]])\n",
      "tensor([[[-0.4362, -0.4921, -0.6597, -0.5138, -0.4186, -0.3135, -0.2826],\n",
      "         [-0.2802, -0.2976, -0.4180, -0.4281, -0.2907, -0.2542, -0.2599],\n",
      "         [-0.6068, -0.2013, -0.5513, -0.6196, -0.5381, -0.4689, -0.2905],\n",
      "         [-0.3766, -0.2744, -0.4037, -0.4393, -0.6281, -0.4368, -0.4736],\n",
      "         [-0.4151, -0.2308, -0.5930, -0.6666, -0.3947, -0.3780, -0.4053],\n",
      "         [-0.3313, -0.1309, -0.3131,  0.0612, -0.5394,  0.0382, -0.3792],\n",
      "         [-0.2522, -0.4408, -0.1761, -0.1116, -0.3369, -0.1710, -0.2875]]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[-0.2125,  0.0534, -0.2916, -0.1761,  0.0158, -0.2332, -0.1467,\n",
      "          -0.0145, -0.1861, -0.1101, -0.0523, -0.1273, -0.1031, -0.0596,\n",
      "          -0.1160],\n",
      "         [-0.1800, -0.2372, -0.1536, -0.1526, -0.1939, -0.1336, -0.1305,\n",
      "          -0.1590, -0.1174, -0.1030, -0.1155, -0.0973, -0.0978, -0.1071,\n",
      "          -0.0935],\n",
      "         [-0.0925,  0.1371,  0.2173, -0.0895,  0.0762,  0.1340, -0.0871,\n",
      "           0.0271,  0.0669, -0.0840, -0.0342, -0.0167, -0.0835, -0.0459,\n",
      "          -0.0328],\n",
      "         [-0.1319, -0.0298, -0.1623, -0.1740,  0.0136, -0.2298, -0.0992,\n",
      "          -0.0636, -0.1097, -0.0869, -0.0763, -0.0901, -0.0848, -0.0785,\n",
      "          -0.0867],\n",
      "         [-0.1194, -0.1414, -0.1093, -0.1510, -0.1914, -0.1324, -0.0948,\n",
      "          -0.1025, -0.0913, -0.0856, -0.0879, -0.0846, -0.0840, -0.0854,\n",
      "          -0.0834],\n",
      "         [-0.0858,  0.0023,  0.0331, -0.0893,  0.0726,  0.1292, -0.0831,\n",
      "          -0.0525, -0.0418, -0.0821, -0.0729, -0.0697, -0.0820, -0.0765,\n",
      "          -0.0746],\n",
      "         [-0.1869,  0.0269, -0.2504, -0.1429, -0.0184, -0.1800, -0.1540,\n",
      "          -0.0071, -0.1977, -0.2113,  0.0522, -0.2896, -0.0957, -0.0673,\n",
      "          -0.1041],\n",
      "         [-0.1607, -0.2067, -0.1395, -0.1277, -0.1545, -0.1154, -0.1360,\n",
      "          -0.1676, -0.1214, -0.1790, -0.2358, -0.1529, -0.0922, -0.0983,\n",
      "          -0.0894],\n",
      "         [-0.0904,  0.0942,  0.1586, -0.0867,  0.0207,  0.0582, -0.0877,\n",
      "           0.0392,  0.0834, -0.0924,  0.1350,  0.2144, -0.0828, -0.0584,\n",
      "          -0.0498],\n",
      "         [-0.1344, -0.0273, -0.1662, -0.1138, -0.0485, -0.1332, -0.2143,\n",
      "           0.0553, -0.2945, -0.1032, -0.0595, -0.1162, -0.2011,  0.0417,\n",
      "          -0.2734],\n",
      "         [-0.1212, -0.1443, -0.1106, -0.1058, -0.1199, -0.0993, -0.1813,\n",
      "          -0.2394, -0.1546, -0.0979, -0.1073, -0.0935, -0.1714, -0.2237,\n",
      "          -0.1474],\n",
      "         [-0.0860,  0.0064,  0.0386, -0.0843, -0.0280, -0.0083, -0.0926,\n",
      "           0.1401,  0.2214, -0.0835, -0.0457, -0.0325, -0.0915,  0.1181,\n",
      "           0.1913],\n",
      "         [-0.0870, -0.0762, -0.0903, -0.2054,  0.0461, -0.2802, -0.2159,\n",
      "           0.0569, -0.2970, -0.1280, -0.0339, -0.1560, -0.1292, -0.0326,\n",
      "          -0.1579],\n",
      "         [-0.0857, -0.0880, -0.0846, -0.1746, -0.2288, -0.1497, -0.1825,\n",
      "          -0.2412, -0.1554, -0.1165, -0.1367, -0.1071, -0.1174, -0.1382,\n",
      "          -0.1078],\n",
      "         [-0.0821, -0.0728, -0.0695, -0.0919,  0.1252,  0.2010, -0.0928,\n",
      "           0.1427,  0.2249, -0.0855, -0.0043,  0.0241, -0.0856, -0.0023,\n",
      "           0.0268]]], grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[ 0.0128,  0.0552,  0.1008, -0.0983, -0.1953],\n",
      "         [-0.2097,  0.0207,  0.0471, -0.4593, -0.2255],\n",
      "         [ 0.0041,  0.2098, -0.4308,  0.4781, -0.1913],\n",
      "         [ 0.1246, -0.1765,  0.1495, -0.0547, -0.2754],\n",
      "         [-0.3541,  0.0339,  0.1014,  0.0883, -0.2278]]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[-0.0802, -0.4318, -0.2106, -0.2507, -0.2195, -0.2874, -0.2487],\n",
      "         [-0.4148, -0.1645, -0.0355,  0.0997, -0.1011, -0.1765, -0.2274],\n",
      "         [-0.1933, -0.3417,  0.2086,  0.1465, -0.3682, -0.0861, -0.2496],\n",
      "         [-0.3666, -0.1981,  0.2518, -0.4142,  0.4219, -0.2053, -0.0804],\n",
      "         [-0.3501,  0.0531, -0.3080,  0.0300,  0.1560, -0.0232,  0.0516],\n",
      "         [-0.2844, -0.4138, -0.2096,  0.3061,  0.0696,  0.0356, -0.1592],\n",
      "         [-0.2784, -0.2662, -0.1436, -0.1227, -0.2114, -0.2240, -0.2726]]],\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# 二维反卷积\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "tensor2d = torch.rand(1,5,5)\n",
    "print(tensor2d)\n",
    "\n",
    "# 反卷积\n",
    "tconv2d1 = nn.ConvTranspose2d(1, 1, 3, 1, 0)\n",
    "toutput1 = tconv2d1(tensor2d)\n",
    "print(toutput1)\n",
    "\n",
    "# stride = kernel_size\n",
    "tconv2d2 = nn.ConvTranspose2d(1, 1, 3, stride=3)\n",
    "toutput2 = tconv2d2(tensor2d)\n",
    "print(toutput2)\n",
    "\n",
    "# padding = 1\n",
    "tconv2d3 = nn.ConvTranspose2d(1, 1, 3, padding=1)\n",
    "toutput3 = tconv2d3(tensor2d)\n",
    "print(toutput3)\n",
    "\n",
    "# dilation = 1\n",
    "tconv2d4 = nn.ConvTranspose2d(1, 1, 3, dilation=1)\n",
    "toutput4 = tconv2d4(tensor2d)\n",
    "print(toutput4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.4451, 0.5683, 0.8254, 0.3104, 0.8716],\n",
      "          [0.0268, 0.6870, 0.4700, 0.9703, 0.2306],\n",
      "          [0.1368, 0.8062, 0.6034, 0.3070, 0.1107],\n",
      "          [0.6039, 0.1038, 0.5454, 0.8023, 0.5882],\n",
      "          [0.4418, 0.6706, 0.5329, 0.8637, 0.8923]],\n",
      "\n",
      "         [[0.7826, 0.7941, 0.9035, 0.2139, 0.1467],\n",
      "          [0.3347, 0.9945, 0.9853, 0.7031, 0.7701],\n",
      "          [0.9933, 0.8748, 0.9373, 0.9814, 0.0519],\n",
      "          [0.2596, 0.4172, 0.1862, 0.2090, 0.2736],\n",
      "          [0.6369, 0.8533, 0.1192, 0.3487, 0.2118]],\n",
      "\n",
      "         [[0.4329, 0.2899, 0.4355, 0.2922, 0.1879],\n",
      "          [0.7810, 0.6442, 0.3583, 0.9661, 0.6339],\n",
      "          [0.6933, 0.5639, 0.0139, 0.4647, 0.6253],\n",
      "          [0.5270, 0.9514, 0.6202, 0.3164, 0.5807],\n",
      "          [0.7493, 0.0165, 0.0427, 0.5036, 0.0890]],\n",
      "\n",
      "         [[0.3933, 0.1000, 0.2868, 0.0167, 0.8351],\n",
      "          [0.7170, 0.6944, 0.8745, 0.1896, 0.8425],\n",
      "          [0.8318, 0.7097, 0.4189, 0.6140, 0.9157],\n",
      "          [0.1605, 0.0364, 0.3937, 0.3394, 0.7608],\n",
      "          [0.0763, 0.6720, 0.4163, 0.9913, 0.3772]],\n",
      "\n",
      "         [[0.4438, 0.8628, 0.2211, 0.3060, 0.8659],\n",
      "          [0.2646, 0.7658, 0.6540, 0.6981, 0.9076],\n",
      "          [0.2596, 0.5143, 0.9950, 0.4830, 0.9504],\n",
      "          [0.4285, 0.2409, 0.0863, 0.1681, 0.6164],\n",
      "          [0.3197, 0.9089, 0.8552, 0.9104, 0.5643]]]])\n",
      "tensor([[[[-0.0464,  0.1369, -0.1837],\n",
      "          [-0.0922, -0.3200, -0.1950],\n",
      "          [-0.0809, -0.0322,  0.2001]],\n",
      "\n",
      "         [[-0.2842, -0.4277,  0.2240],\n",
      "          [-0.0405, -0.2186, -0.1006],\n",
      "          [-0.1757, -0.3716, -0.0155]],\n",
      "\n",
      "         [[-0.1329,  0.0077, -0.2633],\n",
      "          [-0.0453,  0.2699,  0.1602],\n",
      "          [ 0.1374, -0.2928, -0.1617]]]], grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[[-0.1904]]]], grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[[-0.2738, -0.0646,  0.0289,  0.1268, -0.0901],\n",
      "          [ 0.0425, -0.2836, -0.0578, -0.2078, -0.0947],\n",
      "          [-0.0710,  0.0657, -0.0979,  0.1722,  0.0556],\n",
      "          [-0.0344,  0.1544,  0.0210, -0.0081, -0.1382],\n",
      "          [-0.1848, -0.0948,  0.1110, -0.0313, -0.1669]],\n",
      "\n",
      "         [[-0.1736, -0.1376, -0.2563, -0.0103,  0.0163],\n",
      "          [ 0.1849,  0.2737, -0.0292, -0.1376,  0.0015],\n",
      "          [-0.1743,  0.1272, -0.1984, -0.3751, -0.1925],\n",
      "          [ 0.1875, -0.1372, -0.0011, -0.1813, -0.3581],\n",
      "          [-0.0365, -0.2511, -0.3311, -0.3124, -0.2586]],\n",
      "\n",
      "         [[-0.2743, -0.3720, -0.0652, -0.3125,  0.0712],\n",
      "          [-0.1519, -0.3176, -0.2190, -0.3455, -0.1135],\n",
      "          [ 0.0436,  0.0030, -0.0120, -0.2095, -0.1173],\n",
      "          [ 0.1398, -0.1566, -0.2912, -0.0804, -0.4578],\n",
      "          [-0.2379, -0.1241, -0.2233, -0.2146, -0.0177]],\n",
      "\n",
      "         [[-0.3756,  0.0719, -0.1467, -0.1861, -0.0899],\n",
      "          [-0.1156, -0.2140, -0.2729, -0.2347, -0.0669],\n",
      "          [-0.0710, -0.2896, -0.0946,  0.0936, -0.2048],\n",
      "          [ 0.0173,  0.0378, -0.2704, -0.0631, -0.1681],\n",
      "          [-0.0491, -0.2882, -0.1099, -0.0965,  0.0077]],\n",
      "\n",
      "         [[-0.0386, -0.0802,  0.2139,  0.1401, -0.0853],\n",
      "          [ 0.0367,  0.0337,  0.0764,  0.1453,  0.1462],\n",
      "          [ 0.1695,  0.0842, -0.1622, -0.0012, -0.0549],\n",
      "          [ 0.2642,  0.2319,  0.3243,  0.3079,  0.1483],\n",
      "          [-0.0259, -0.1691, -0.1916, -0.1211, -0.1458]]]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[[-0.2962, -0.5237, -0.3397],\n",
      "          [-0.2084, -0.2672, -0.3143],\n",
      "          [-0.2196, -0.5383, -0.3388]],\n",
      "\n",
      "         [[-0.5319, -0.3735, -0.2589],\n",
      "          [-0.4778, -0.4437,  0.0302],\n",
      "          [-0.4401, -0.3914, -0.1340]],\n",
      "\n",
      "         [[-0.2068, -0.3823, -0.2225],\n",
      "          [-0.1383, -0.2684, -0.6785],\n",
      "          [-0.2608, -0.1498,  0.0959]]]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# 三维卷积\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "tensor3d = torch.rand(1,5,5,5)\n",
    "print(tensor3d)\n",
    "\n",
    "# 卷积\n",
    "conv3d1 = nn.Conv3d(1, 1, 3, 1, 0)\n",
    "output1 = conv3d1(tensor3d)\n",
    "print(output1)\n",
    "\n",
    "# stride = kernel_size\n",
    "conv3d2 = nn.Conv3d(1, 1, 3, stride=3)\n",
    "output2 = conv3d2(tensor3d)\n",
    "print(output2)\n",
    "\n",
    "# padding = 1\n",
    "conv3d3 = nn.Conv3d(1, 1, 3, padding=1)\n",
    "output3 = conv3d3(tensor3d)\n",
    "print(output3)\n",
    "\n",
    "# dilation = 1\n",
    "conv3d4 = nn.Conv3d(1, 1, 3, dilation=1)\n",
    "output4 = conv3d4(tensor3d)\n",
    "print(output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.6753, 0.0724, 0.5433, 0.0829, 0.0396],\n",
      "          [0.8942, 0.3764, 0.3324, 0.7251, 0.2079],\n",
      "          [0.4272, 0.2404, 0.0851, 0.2158, 0.1177],\n",
      "          [0.6906, 0.2156, 0.7618, 0.1438, 0.5032],\n",
      "          [0.6594, 0.2223, 0.1913, 0.5082, 0.9875]],\n",
      "\n",
      "         [[0.6859, 0.7394, 0.1791, 0.4298, 0.9677],\n",
      "          [0.5522, 0.0387, 0.1341, 0.8716, 0.0293],\n",
      "          [0.3386, 0.3591, 0.6576, 0.4810, 0.8562],\n",
      "          [0.5275, 0.5759, 0.9991, 0.2837, 0.2974],\n",
      "          [0.3247, 0.2239, 0.9817, 0.1862, 0.3543]],\n",
      "\n",
      "         [[0.0186, 0.0204, 0.2931, 0.6085, 0.3056],\n",
      "          [0.9286, 0.1930, 0.1847, 0.6156, 0.7689],\n",
      "          [0.0876, 0.0396, 0.4381, 0.5861, 0.9038],\n",
      "          [0.2577, 0.5910, 0.1867, 0.9597, 0.2282],\n",
      "          [0.2848, 0.9003, 0.7803, 0.9303, 0.6785]],\n",
      "\n",
      "         [[0.2191, 0.3915, 0.1691, 0.4472, 0.4859],\n",
      "          [0.2490, 0.6723, 0.9480, 0.2127, 0.8485],\n",
      "          [0.8084, 0.7618, 0.3589, 0.1493, 0.2852],\n",
      "          [0.2057, 0.6764, 0.1900, 0.6334, 0.1262],\n",
      "          [0.8541, 0.6487, 0.0644, 0.0071, 0.2937]],\n",
      "\n",
      "         [[0.3918, 0.8008, 0.5917, 0.8998, 0.2220],\n",
      "          [0.7583, 0.7574, 0.8690, 0.3359, 0.5157],\n",
      "          [0.9441, 0.4931, 0.0180, 0.8518, 0.5228],\n",
      "          [0.1136, 0.1984, 0.0374, 0.0154, 0.4802],\n",
      "          [0.5187, 0.7916, 0.7755, 0.7047, 0.6263]]]])\n",
      "tensor([[[[-0.2923, -0.2857, -0.2547, -0.2645, -0.1679, -0.1705, -0.1659],\n",
      "          [-0.4430, -0.2811, -0.2347, -0.2568, -0.2214, -0.1551, -0.1541],\n",
      "          [-0.3635, -0.2261, -0.1769, -0.2581, -0.1945, -0.0576, -0.1405],\n",
      "          [-0.3267, -0.3111, -0.4010, -0.3461, -0.3144, -0.3354, -0.1709],\n",
      "          [-0.3839, -0.2463, -0.2911, -0.1946, -0.3924, -0.2478, -0.0809],\n",
      "          [-0.2455, -0.1218, -0.1746, -0.2569, -0.3479,  0.0122, -0.1188],\n",
      "          [-0.1392, -0.1880, -0.2924, -0.1959, -0.1842, -0.3074, -0.3517]],\n",
      "\n",
      "         [[-0.3580, -0.3863, -0.4320, -0.2406, -0.4819, -0.3118, -0.1378],\n",
      "          [-0.5580, -0.2250, -0.0767, -0.3452, -0.3011,  0.0017, -0.0483],\n",
      "          [-0.5465, -0.3302, -0.5255, -0.7707, -0.2654, -0.1754, -0.2977],\n",
      "          [-0.5437, -0.5959, -0.8499, -0.4614, -0.6106, -0.2602, -0.1183],\n",
      "          [-0.5146, -0.3520, -0.6040, -0.3030, -0.2813, -0.2720, -0.3355],\n",
      "          [-0.3833, -0.2938, -0.4686, -0.3640, -0.5140, -0.1021, -0.0700],\n",
      "          [-0.2447, -0.3293, -0.3644, -0.3863, -0.6064, -0.4833, -0.3819]],\n",
      "\n",
      "         [[-0.2821, -0.2472, -0.2611, -0.4807, -0.3450, -0.1993, -0.2856],\n",
      "          [-0.4812, -0.4301, -0.0854, -0.3593, -0.3900, -0.0230,  0.0973],\n",
      "          [-0.5478, -0.4172, -0.4813, -0.8004, -0.8437, -0.3521, -0.3392],\n",
      "          [-0.4623, -0.7371, -0.9205, -0.7290, -0.8021, -0.2044, -0.0234],\n",
      "          [-0.4292, -0.7218, -0.6618, -0.6464, -0.7641, -0.4119, -0.3190],\n",
      "          [-0.3274, -0.5708, -0.7478, -0.5046, -0.2302, -0.2827, -0.1797],\n",
      "          [-0.2708, -0.3839, -0.5616, -0.6836, -0.7736, -0.6883, -0.4119]],\n",
      "\n",
      "         [[-0.2570, -0.3566, -0.2436, -0.2574, -0.4263, -0.2883, -0.0755],\n",
      "          [-0.3080, -0.2859, -0.5050, -0.5101, -0.2544,  0.0173, -0.1672],\n",
      "          [-0.5268, -0.7022, -0.5708, -0.3527, -0.7747, -0.4064, -0.1201],\n",
      "          [-0.5527, -0.6847, -0.4667, -0.7441, -0.6955, -0.4276, -0.2775],\n",
      "          [-0.4039, -0.7295, -0.5252, -0.8687, -0.6950, -0.5121, -0.4101],\n",
      "          [-0.3962, -0.4886, -0.3456, -0.5823, -0.5560, -0.2965, -0.0997],\n",
      "          [-0.2051, -0.4432, -0.8454, -0.9249, -0.6935, -0.5309, -0.3474]],\n",
      "\n",
      "         [[-0.2618, -0.4055, -0.4341, -0.5380, -0.3883, -0.1490, -0.1898],\n",
      "          [-0.4872, -0.6354, -0.2592, -0.2877, -0.3362,  0.0649, -0.0709],\n",
      "          [-0.5037, -0.5849, -0.5743, -0.4730, -0.7533, -0.4282, -0.0285],\n",
      "          [-0.5828, -0.6372, -0.3722, -0.7710, -0.8107, -0.4582, -0.3366],\n",
      "          [-0.4650, -0.8237, -1.0324, -0.7291, -0.7623, -0.4641, -0.2237],\n",
      "          [-0.3909, -0.3873, -0.1965, -0.3173, -0.4170, -0.2410, -0.1847],\n",
      "          [-0.2939, -0.5607, -0.8016, -0.7380, -0.6696, -0.5743, -0.3728]],\n",
      "\n",
      "         [[-0.2194, -0.2615, -0.2431, -0.3270, -0.2617, -0.2496, -0.1395],\n",
      "          [-0.2873, -0.2999, -0.3271, -0.1488, -0.0880, -0.0460, -0.1231],\n",
      "          [-0.4681, -0.5043, -0.4780, -0.5676, -0.4557, -0.4633, -0.2241],\n",
      "          [-0.3708, -0.5202, -0.6200, -0.7892, -0.6839, -0.2144, -0.2733],\n",
      "          [-0.4871, -0.7335, -0.6394, -0.4976, -0.6866, -0.5345, -0.2366],\n",
      "          [-0.1894, -0.3271, -0.3790, -0.2837, -0.2545, -0.1515, -0.1513],\n",
      "          [-0.3307, -0.6075, -0.6896, -0.5873, -0.5422, -0.4491, -0.2807]],\n",
      "\n",
      "         [[-0.1944, -0.2401, -0.1967, -0.1594, -0.1516, -0.0688, -0.1406],\n",
      "          [-0.1800, -0.1707, -0.1278, -0.0880, -0.1191, -0.1979, -0.1173],\n",
      "          [-0.1977, -0.3239, -0.2679, -0.4321, -0.4662, -0.2051, -0.1469],\n",
      "          [-0.1609, -0.3572, -0.4991, -0.3371, -0.3170, -0.3509, -0.1717],\n",
      "          [-0.2929, -0.4565, -0.3525, -0.2914, -0.3208, -0.2641, -0.1522],\n",
      "          [-0.1270, -0.1278, -0.1627, -0.1575, -0.2000, -0.2951, -0.2328],\n",
      "          [-0.2230, -0.3506, -0.4346, -0.4418, -0.4189, -0.3322, -0.2083]]]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[[0.1691, 0.2864, 0.2137,  ..., 0.1817, 0.1885, 0.1843],\n",
      "          [0.1095, 0.2901, 0.2570,  ..., 0.1782, 0.1888, 0.1868],\n",
      "          [0.2938, 0.2372, 0.0642,  ..., 0.1890, 0.1857, 0.1755],\n",
      "          ...,\n",
      "          [0.1694, 0.2839, 0.2129,  ..., 0.1630, 0.3344, 0.2281],\n",
      "          [0.1113, 0.2875, 0.2553,  ..., 0.0758, 0.3398, 0.2915],\n",
      "          [0.2912, 0.2359, 0.0670,  ..., 0.3453, 0.2625, 0.0095]],\n",
      "\n",
      "         [[0.3029, 0.2132, 0.2949,  ..., 0.1895, 0.1843, 0.1890],\n",
      "          [0.2122, 0.1298, 0.0957,  ..., 0.1842, 0.1794, 0.1774],\n",
      "          [0.2560, 0.1028, 0.1577,  ..., 0.1868, 0.1778, 0.1810],\n",
      "          ...,\n",
      "          [0.3001, 0.2125, 0.2922,  ..., 0.3586, 0.2274, 0.3469],\n",
      "          [0.2115, 0.1311, 0.0977,  ..., 0.2260, 0.1055, 0.0556],\n",
      "          [0.2542, 0.1047, 0.1582,  ..., 0.2900, 0.0660, 0.1462]],\n",
      "\n",
      "         [[0.2828, 0.0912, 0.2091,  ..., 0.1883, 0.1771, 0.1840],\n",
      "          [0.1019, 0.2360, 0.2764,  ..., 0.1777, 0.1856, 0.1880],\n",
      "          [0.0908, 0.1598, 0.2647,  ..., 0.1771, 0.1811, 0.1873],\n",
      "          ...,\n",
      "          [0.2804, 0.0934, 0.2085,  ..., 0.3292, 0.0490, 0.2215],\n",
      "          [0.1038, 0.2347, 0.2742,  ..., 0.0647, 0.2607, 0.3199],\n",
      "          [0.0929, 0.1604, 0.2627,  ..., 0.0484, 0.1494, 0.3027]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.1747, 0.2428, 0.2006,  ..., 0.1781, 0.2166, 0.1927],\n",
      "          [0.1401, 0.2449, 0.2257,  ..., 0.1585, 0.2178, 0.2070],\n",
      "          [0.2471, 0.2142, 0.1138,  ..., 0.2191, 0.2005, 0.1436],\n",
      "          ...,\n",
      "          [0.1722, 0.2623, 0.2064,  ..., 0.1701, 0.2788, 0.2114],\n",
      "          [0.1264, 0.2651, 0.2397,  ..., 0.1148, 0.2823, 0.2516],\n",
      "          [0.2680, 0.2245, 0.0916,  ..., 0.2857, 0.2332, 0.0728]],\n",
      "\n",
      "         [[0.2523, 0.2003, 0.2477,  ..., 0.2221, 0.1926, 0.2194],\n",
      "          [0.1997, 0.1519, 0.1321,  ..., 0.1922, 0.1652, 0.1539],\n",
      "          [0.2251, 0.1362, 0.1681,  ..., 0.2066, 0.1563, 0.1743],\n",
      "          ...,\n",
      "          [0.2750, 0.2061, 0.2688,  ..., 0.2942, 0.2110, 0.2867],\n",
      "          [0.2053, 0.1420, 0.1158,  ..., 0.2100, 0.1337, 0.1020],\n",
      "          [0.2389, 0.1213, 0.1634,  ..., 0.2506, 0.1086, 0.1595]],\n",
      "\n",
      "         [[0.2407, 0.1295, 0.1979,  ..., 0.2154, 0.1524, 0.1912],\n",
      "          [0.1357, 0.2135, 0.2370,  ..., 0.1560, 0.2000, 0.2133],\n",
      "          [0.1293, 0.1693, 0.2302,  ..., 0.1523, 0.1750, 0.2095],\n",
      "          ...,\n",
      "          [0.2595, 0.1124, 0.2030,  ..., 0.2755, 0.0978, 0.2072],\n",
      "          [0.1206, 0.2236, 0.2546,  ..., 0.1078, 0.2321, 0.2696],\n",
      "          [0.1120, 0.1651, 0.2456,  ..., 0.0974, 0.1615, 0.2587]]]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[[ 0.1800,  0.2202,  0.3478,  0.2327,  0.0954],\n",
      "          [-0.0408,  0.0880,  0.0575, -0.1354,  0.0442],\n",
      "          [ 0.2099,  0.1715,  0.0141,  0.2155,  0.1159],\n",
      "          [ 0.1339,  0.2538, -0.0203,  0.2553,  0.1253],\n",
      "          [-0.0442,  0.0759,  0.1162,  0.0149,  0.0159]],\n",
      "\n",
      "         [[-0.0753, -0.2262,  0.2120,  0.1565, -0.2563],\n",
      "          [ 0.2328,  0.4255, -0.0314,  0.3721,  0.2730],\n",
      "          [ 0.1700, -0.0345,  0.3056, -0.1192, -0.0390],\n",
      "          [ 0.2755, -0.1296,  0.2916, -0.1083,  0.0810],\n",
      "          [ 0.1646,  0.3058,  0.1283,  0.2792,  0.4175]],\n",
      "\n",
      "         [[ 0.3797,  0.1841, -0.0588,  0.2143,  0.1434],\n",
      "          [ 0.0831,  0.1007,  0.0859,  0.3523,  0.0573],\n",
      "          [ 0.2696, -0.0975,  0.2862, -0.1329,  0.0801],\n",
      "          [ 0.0786,  0.0966,  0.5268,  0.2036,  0.1959],\n",
      "          [ 0.0713,  0.1308,  0.0543,  0.1347, -0.0159]],\n",
      "\n",
      "         [[ 0.1768,  0.0796,  0.2100,  0.1561,  0.1964],\n",
      "          [ 0.2608,  0.1961,  0.2237,  0.1376,  0.0239],\n",
      "          [-0.0666,  0.1616,  0.1622,  0.2855,  0.1537],\n",
      "          [ 0.1124,  0.0649, -0.4150, -0.0705, -0.0490],\n",
      "          [ 0.0368,  0.3774,  0.5607,  0.3736,  0.2788]],\n",
      "\n",
      "         [[ 0.0090,  0.0164, -0.0369, -0.1883,  0.2430],\n",
      "          [ 0.0439, -0.1591,  0.0221,  0.1320,  0.0386],\n",
      "          [ 0.0367,  0.2239, -0.1694, -0.0901, -0.0384],\n",
      "          [ 0.1717,  0.0320,  0.0655,  0.2934,  0.0201],\n",
      "          [ 0.0452,  0.0416,  0.0436, -0.1265,  0.0811]]]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[[-0.1295, -0.0790, -0.0488, -0.0854, -0.0861, -0.1464, -0.1560],\n",
      "          [-0.2384, -0.1070, -0.0742, -0.1009, -0.0218, -0.0524, -0.1350],\n",
      "          [-0.3613, -0.2535, -0.0896, -0.2573, -0.1301, -0.1003, -0.1335],\n",
      "          [-0.2873, -0.1933,  0.0537, -0.0941, -0.0477,  0.0143, -0.0680],\n",
      "          [-0.2917, -0.1953, -0.1250, -0.1549, -0.1073,  0.0070, -0.0103],\n",
      "          [-0.3410, -0.2815, -0.1623, -0.2489, -0.3080, -0.2070, -0.0518],\n",
      "          [-0.2220, -0.1892, -0.0866, -0.1784, -0.2312, -0.0996, -0.0192]],\n",
      "\n",
      "         [[-0.2108, -0.0268,  0.0613, -0.0089,  0.0426,  0.0168, -0.0417],\n",
      "          [-0.4034, -0.3470,  0.0378, -0.2128, -0.1058,  0.0193, -0.0809],\n",
      "          [-0.4992, -0.4118, -0.0009, -0.1862, -0.2317,  0.1943,  0.1242],\n",
      "          [-0.4742, -0.3526, -0.1891, -0.2796, -0.2414, -0.0751, -0.0191],\n",
      "          [-0.4466, -0.4336, -0.2277, -0.2481, -0.0759,  0.0122,  0.2371],\n",
      "          [-0.3967, -0.4462, -0.5121, -0.3527, -0.3488, -0.2154, -0.0251],\n",
      "          [-0.2782, -0.2765, -0.3494, -0.2749, -0.2612, -0.3039, -0.2522]],\n",
      "\n",
      "         [[-0.2105, -0.1434,  0.1107,  0.0520, -0.0225,  0.0738,  0.0395],\n",
      "          [-0.1894,  0.0349,  0.2267, -0.0716,  0.0109,  0.2591,  0.1242],\n",
      "          [-0.4386, -0.4408, -0.0899, -0.4268, -0.2556,  0.2189,  0.0441],\n",
      "          [-0.3339, -0.2587,  0.0903, -0.0946, -0.0831,  0.0650,  0.2772],\n",
      "          [-0.2682, -0.2850, -0.1767, -0.1102,  0.0479,  0.2553,  0.1919],\n",
      "          [-0.2945, -0.5762, -0.5411, -0.6716, -0.3171, -0.0741, -0.0414],\n",
      "          [-0.1983, -0.3652, -0.3580, -0.2526, -0.3173, -0.1536, -0.0295]],\n",
      "\n",
      "         [[-0.1200, -0.0118,  0.0709,  0.0128,  0.0875,  0.2236,  0.0850],\n",
      "          [-0.2792, -0.0651,  0.2101, -0.0545, -0.0205,  0.3496,  0.1398],\n",
      "          [-0.2090, -0.2415, -0.0121, -0.0638, -0.1922,  0.0417,  0.4031],\n",
      "          [-0.4263, -0.5015, -0.0916,  0.0888, -0.0819,  0.1676,  0.1028],\n",
      "          [-0.2654, -0.3490,  0.0896,  0.0863, -0.1445,  0.0898,  0.0618],\n",
      "          [-0.3575, -0.5900, -0.3337, -0.2787, -0.2552, -0.1439, -0.0321],\n",
      "          [-0.2622, -0.3998, -0.2286, -0.4682, -0.3859, -0.3813, -0.1858]],\n",
      "\n",
      "         [[-0.1682, -0.1134,  0.0562,  0.1225,  0.1312,  0.1833, -0.0111],\n",
      "          [-0.1933, -0.2142,  0.0101,  0.1087,  0.1118,  0.2510,  0.2342],\n",
      "          [-0.4294, -0.4100, -0.1566, -0.0426,  0.1007,  0.2499,  0.2197],\n",
      "          [-0.4405, -0.7015, -0.0775, -0.0823, -0.2492,  0.1371,  0.0355],\n",
      "          [-0.4508, -0.3578,  0.2704,  0.2976,  0.0788,  0.3099,  0.2081],\n",
      "          [-0.3288, -0.5598, -0.3373, -0.2577, -0.4483, -0.1966, -0.0175],\n",
      "          [-0.3083, -0.3924, -0.3911, -0.1807, -0.1612, -0.0856, -0.0549]],\n",
      "\n",
      "         [[-0.1975, -0.1990, -0.0529, -0.0172,  0.0427,  0.1118, -0.0543],\n",
      "          [-0.2646, -0.2253,  0.0343,  0.2021,  0.1709,  0.1975,  0.0832],\n",
      "          [-0.3232, -0.2960,  0.0558, -0.1766, -0.2168, -0.0316,  0.0609],\n",
      "          [-0.3130, -0.3379, -0.1595, -0.1887, -0.3219, -0.0873,  0.0175],\n",
      "          [-0.2766, -0.3233, -0.0658, -0.0905, -0.1504, -0.1975,  0.0085],\n",
      "          [-0.2014, -0.2118, -0.2173, -0.0987, -0.2493, -0.0857, -0.1205],\n",
      "          [-0.1881, -0.3709, -0.4026, -0.3912, -0.4024, -0.3505, -0.2256]],\n",
      "\n",
      "         [[-0.1419, -0.0814,  0.0077,  0.0593,  0.0291, -0.0082, -0.1287],\n",
      "          [-0.1269, -0.0196,  0.1304,  0.1006,  0.0967, -0.0354, -0.0851],\n",
      "          [-0.1015,  0.0143,  0.0655,  0.0747, -0.0468,  0.1134, -0.0632],\n",
      "          [-0.1247, -0.1102, -0.0483, -0.1368, -0.0022, -0.0862, -0.0440],\n",
      "          [-0.0910, -0.1345,  0.0809,  0.1536, -0.0084,  0.0631, -0.0227],\n",
      "          [-0.1585, -0.1273, -0.1092, -0.0855, -0.0798, -0.1553, -0.1153],\n",
      "          [-0.1356, -0.1759, -0.1602, -0.1385, -0.1364, -0.1646, -0.1067]]]],\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# 三维反卷积\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "tensor3d = torch.rand(1,5,5,5)\n",
    "print(tensor3d)\n",
    "\n",
    "# 反卷积\n",
    "tconv3d1 = nn.ConvTranspose3d(1, 1, 3, 1, 0)\n",
    "toutput1 = tconv3d1(tensor3d)\n",
    "print(toutput1)\n",
    "\n",
    "# stride = kernel_size\n",
    "tconv3d2 = nn.ConvTranspose3d(1, 1, 3, stride=3)\n",
    "toutput2 = tconv3d2(tensor3d)\n",
    "print(toutput2)\n",
    "\n",
    "# padding = 1\n",
    "tconv3d3 = nn.ConvTranspose3d(1, 1, 3, padding=1)\n",
    "toutput3 = tconv3d3(tensor3d)\n",
    "print(toutput3)\n",
    "\n",
    "# dilation = 1\n",
    "tconv3d4 = nn.ConvTranspose3d(1, 1, 3, dilation=1)\n",
    "toutput4 = tconv3d4(tensor3d)\n",
    "print(toutput4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Pooling layers 池化层\n",
    "|类|简介|\n",
    "|---|---|\n",
    "|nn.MaxPool1d|一维最大池化|\n",
    "|nn.MaxPool2d|二维最大池化|\n",
    "|nn.MaxPool3d|三维最大池化|\n",
    "|nn.MaxUnpool1d|一维反最大池化|\n",
    "|nn.MaxUnpool2d|二维反最大池化|\n",
    "|nn.MaxUnpool3d|三维反最大池化|\n",
    "|nn.AvgPool1d|一维平均池化|\n",
    "|nn.AvgPool2d|二维平均池化|\n",
    "|nn.AvgPool3d|三维平均池化|\n",
    "|nn.FractionalMaxPool1d|一维分数最大池化|\n",
    "|nn.FractionalMaxPool2d|二维分数最大池化|\n",
    "|nn.FractionalMaxPool3d|三维分数最大池化|\n",
    "|nn.LPPool1d|一维LP池化|\n",
    "|nn.LPPool2d|二维LP池化|\n",
    "|nn.LPPool3d|三维LP池化|\n",
    "|nn.AdaptiveMaxPool1d|一维自适应最大池化|\n",
    "|nn.AdaptiveMaxPool2d|二维自适应最大池化|\n",
    "|nn.AdaptiveMaxPool3d|三维自适应最大池化|\n",
    "|nn.AdaptiveAvgPool1d|一维自适应平均池化|\n",
    "|nn.AdaptiveAvgPool2d|二维自适应平均池化|\n",
    "|nn.AdaptiveAvgPool3d|三维自适应平均池化|\n",
    "\n",
    "#### 池化\n",
    "由于参与运算的张量太大时，会影响计算速度和计算结果，所以需要使用池化对张量进行采样，提取图像特征，减少运算量等。\n",
    "#### 池化特点\n",
    "* 池化层没有训练参数\n",
    "* 只改变特征矩阵的W和H，不改变channel（深度）（如果一个4 x 4 x3 （WHC）的矩阵，若经大小为2 x 2、且布距也为2 的池化核操作，最终会得到2 x 2 x 3 的矩阵结果）\n",
    "* 一般pool size（池化核大小）和 stride（步距）相同\n",
    "#### 池化作用\n",
    "* 下采样（downsamping），降维、去除冗余信息，同时增大了感受视野，保留feature map的特征信息，降低参数量\n",
    "* 可以实现特征不变性（feature invariant）\n",
    "* 实现非线性，在一定程度上能防止过拟合的发生\n",
    "#### MaxPool 最大池化\n",
    "选定某一卷积核的区域，取这个区域中输入张量的最大值。\n",
    "|||||\n",
    "|---|---|---|---|\n",
    "|1|1|2|4|\n",
    "|5|6|7|8|\n",
    "|3|2|1|0|\n",
    "|1|2|3|4|\n",
    "\n",
    "-MaxPool->\n",
    "\n",
    "|||\n",
    "|---|---|\n",
    "|6|8|\n",
    "|3|4|\n",
    "\n",
    "```python\n",
    "torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "```\n",
    "**Parameters**\n",
    "* kernel_size   - 池化核大小\n",
    "* stride        - 池化步长\n",
    "* padding       - 填充数目\n",
    "* dilation      - 池化核点间隔\n",
    "* return_indices    - 为True时返回最大值点位置索引\n",
    "* ceil_mode     - 为Ture时用向上取整的方法计算输出形状，默认是向下取整\n",
    "#### AvgPool 平均池化\n",
    "选定某一卷积核的区域，取这个区域中输入张量的平均值。\n",
    "|||||\n",
    "|---|---|---|---|\n",
    "|1|1|2|4|\n",
    "|5|6|7|8|\n",
    "|3|2|1|0|\n",
    "|1|2|3|4|\n",
    "\n",
    "-AvgPool->\n",
    "\n",
    "|||\n",
    "|---|---|\n",
    "|3.25|5.25|\n",
    "|2|2|\n",
    "\n",
    "```python\n",
    "torch.nn.AvgPool2d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None)\n",
    "```\n",
    "**Parameters**\n",
    "* kernel_size   - 池化核大小\n",
    "* stride        - 池化步长\n",
    "* padding       - 填充数目\n",
    "* ceil_mode     - 为Ture时用向上取整的方法计算输出形状，默认是向下取整\n",
    "* count_include_pad - 为True时将把zero-padding的内容一起计算\n",
    "* divisor_override  - 指定时将使用该数字作为除数，否则为池化核大小\n",
    "#### 自适应池化\n",
    "AdaptivePooling，自适应池化层。函数通过输入原始尺寸和目标尺寸，自适应地计算核的大小和每次移动的步长。如告诉函数原来的矩阵是7x7的尺寸，我要得到3x1的尺寸，函数就会自己计算出核多大、该怎么运动。\n",
    "#### MaxUnpool 反池化\n",
    "通过接受Maxpool的结果和最大值索引，进行部分Maxpool的逆运算。\n",
    "```python\n",
    "torch.nn.MaxUnpool2d(kernel_size, stride=None, padding=0)\n",
    "```\n",
    "**Parameters**\n",
    "* kernel_size   - 池化核大小\n",
    "* stride        - 池化步长\n",
    "* padding       - 填充数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(\"./data\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=64)\n",
    "\n",
    "class MyPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyPool, self).__init__()\n",
    "        self.maxpoll1 = nn.MaxPool2d(kernel_size=3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.maxpoll1(x)\n",
    "        return y\n",
    "\n",
    "myPool = MyPool()\n",
    "writer = SummaryWriter(\"./logs\")\n",
    "step = 0\n",
    "for data in dataloader:\n",
    "    img, target = data\n",
    "    output = myPool(img)\n",
    "    if(step == 0):\n",
    "        print(img.shape)\n",
    "        print(output.shape)\n",
    "    writer.add_images(\"pool_input\", img, step)\n",
    "    writer.add_images(\"pool_output\", output, step)\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8541, 0.1400, 0.2403, 0.9580, 0.8378, 0.1185]])\n",
      "tensor([[0.8541, 0.9580, 0.8378]])\n",
      "tensor([[0.8541, 0.8378]])\n",
      "tensor([[0.8541, 0.2403, 0.9580, 0.1185]])\n",
      "tensor([[0.8541, 0.9580, 0.8378]])\n"
     ]
    }
   ],
   "source": [
    "# 一维池化\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "tensor1d = torch.rand(1,6)\n",
    "print(tensor1d)\n",
    "\n",
    "# 最大池化\n",
    "mp1d1 = nn.MaxPool1d(2)\n",
    "output1 = mp1d1(tensor1d)\n",
    "print(output1)\n",
    "\n",
    "# stride = 4\n",
    "mp1d2 = nn.MaxPool1d(2, stride=4)\n",
    "output2 = mp1d2(tensor1d)\n",
    "print(output2)\n",
    "\n",
    "# padding = 1\n",
    "mp1d3 = nn.MaxPool1d(2, padding=1)\n",
    "output3 = mp1d3(tensor1d)\n",
    "print(output3)\n",
    "\n",
    "# dilation = 1\n",
    "mp1d4 = nn.MaxPool1d(2, dilation=1)\n",
    "output4 = mp1d4(tensor1d)\n",
    "print(output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5980, 0.6691, 0.4889, 0.4031, 0.2867, 0.2234]])\n",
      "tensor([[0.0000, 0.6691, 0.4889, 0.0000, 0.2867, 0.0000]])\n",
      "tensor([[0.0000, 0.6691, 0.0000, 0.0000, 0.2867, 0.0000]])\n",
      "tensor([[0.5980, 0.6691, 0.0000, 0.4031, 0.0000, 0.2234]])\n",
      "tensor([[0.0000, 0.6691, 0.4889, 0.0000, 0.2867, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# 一维反池化\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "tensor1d = torch.rand(1,6)\n",
    "print(tensor1d)\n",
    "\n",
    "# 最大反池化\n",
    "mp1d1 = nn.MaxPool1d(2, return_indices=True)\n",
    "output1, idx1 = mp1d1(tensor1d)\n",
    "ump1d1 = nn.MaxUnpool1d(2)\n",
    "output1 = ump1d1(output1,idx1)\n",
    "print(output1)\n",
    "\n",
    "# stride = 4\n",
    "mp1d2 = nn.MaxPool1d(2, stride=4, return_indices=True)\n",
    "output2, idx2 = mp1d2(tensor1d)\n",
    "ump1d2 = nn.MaxUnpool1d(2, stride=4)\n",
    "output2 = ump1d2(output2,idx2)\n",
    "print(output2)\n",
    "\n",
    "# padding = 1\n",
    "mp1d3 = nn.MaxPool1d(2, padding=1, return_indices=True)\n",
    "output3, idx3 = mp1d3(tensor1d)\n",
    "ump1d3 = nn.MaxUnpool1d(2, padding=1)\n",
    "output3 = ump1d3(output3,idx3)\n",
    "print(output3)\n",
    "\n",
    "# dilation = 1\n",
    "mp1d4 = nn.MaxPool1d(2, dilation=1, return_indices=True)\n",
    "output4, idx4 = mp1d4(tensor1d)\n",
    "ump1d4 = nn.MaxUnpool1d(2)\n",
    "output4 = ump1d4(output4,idx4)\n",
    "print(output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6450, 0.3877, 0.3982, 0.4910, 0.7893, 0.4247]])\n",
      "tensor([[0.5163, 0.4446, 0.6070]])\n",
      "tensor([[0.5163, 0.6070]])\n",
      "tensor([[0.3225, 0.3930, 0.6402, 0.2124]])\n"
     ]
    }
   ],
   "source": [
    "# 一维池化\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "tensor1d = torch.rand(1,6)\n",
    "print(tensor1d)\n",
    "\n",
    "# 平均池化\n",
    "ap1d1 = nn.AvgPool1d(2)\n",
    "output1 = ap1d1(tensor1d)\n",
    "print(output1)\n",
    "\n",
    "# stride = 4\n",
    "ap1d2 = nn.AvgPool1d(2, stride=4)\n",
    "output2 = ap1d2(tensor1d)\n",
    "print(output2)\n",
    "\n",
    "# padding = 1\n",
    "ap1d3 = nn.AvgPool1d(2, padding=1)\n",
    "output3 = ap1d3(tensor1d)\n",
    "print(output3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6086, 0.6699, 0.0470, 0.4770, 0.8332, 0.6735],\n",
      "         [0.6610, 0.8052, 0.9347, 0.4431, 0.2395, 0.2540],\n",
      "         [0.7358, 0.7348, 0.6830, 0.2110, 0.2055, 0.5493],\n",
      "         [0.2866, 0.9834, 0.1148, 0.2369, 0.8626, 0.8409],\n",
      "         [0.6592, 0.8388, 0.9594, 0.4033, 0.6398, 0.1160],\n",
      "         [0.7909, 0.9909, 0.5988, 0.6057, 0.1971, 0.0481]]])\n",
      "tensor([[[0.8052, 0.9347, 0.8332],\n",
      "         [0.9834, 0.6830, 0.8626],\n",
      "         [0.9909, 0.9594, 0.6398]]])\n",
      "tensor([[[0.8052, 0.8332],\n",
      "         [0.9909, 0.6398]]])\n",
      "tensor([[[0.6086, 0.6699, 0.8332, 0.6735],\n",
      "         [0.7358, 0.9347, 0.4431, 0.5493],\n",
      "         [0.6592, 0.9834, 0.8626, 0.8409],\n",
      "         [0.7909, 0.9909, 0.6057, 0.0481]]])\n",
      "tensor([[[0.8052, 0.9347, 0.8332],\n",
      "         [0.9834, 0.6830, 0.8626],\n",
      "         [0.9909, 0.9594, 0.6398]]])\n"
     ]
    }
   ],
   "source": [
    "# 二维池化\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "tensor2d = torch.rand(1,6,6)\n",
    "print(tensor2d)\n",
    "\n",
    "# 最大池化\n",
    "mp2d1 = nn.MaxPool2d(2)\n",
    "output1 = mp2d1(tensor2d)\n",
    "print(output1)\n",
    "\n",
    "# stride = 4\n",
    "mp2d2 = nn.MaxPool2d(2, stride=4)\n",
    "output2 = mp2d2(tensor2d)\n",
    "print(output2)\n",
    "\n",
    "# padding = 1\n",
    "mp2d3 = nn.MaxPool2d(2, padding=1)\n",
    "output3 = mp2d3(tensor2d)\n",
    "print(output3)\n",
    "\n",
    "# dilation = 1\n",
    "mp2d4 = nn.MaxPool2d(2, dilation=1)\n",
    "output4 = mp2d4(tensor2d)\n",
    "print(output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1790, 0.7364, 0.2423, 0.0471, 0.8842, 0.8169],\n",
      "         [0.1822, 0.0582, 0.5224, 0.3118, 0.5211, 0.0327],\n",
      "         [0.0256, 0.5196, 0.9729, 0.6414, 0.4264, 0.7861],\n",
      "         [0.1053, 0.6249, 0.1260, 0.9544, 0.8521, 0.8469],\n",
      "         [0.2706, 0.5002, 0.2789, 0.4326, 0.7401, 0.4363],\n",
      "         [0.7421, 0.8574, 0.3633, 0.1962, 0.9472, 0.6615]]])\n",
      "tensor([[[0.0000, 0.7364, 0.0000, 0.0000, 0.8842, 0.0000],\n",
      "         [0.0000, 0.0000, 0.5224, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.9729, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6249, 0.0000, 0.0000, 0.8521, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4326, 0.0000, 0.0000],\n",
      "         [0.0000, 0.8574, 0.0000, 0.0000, 0.9472, 0.0000]]])\n",
      "tensor([[[0.0000, 0.7364, 0.0000, 0.0000, 0.8842, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.8574, 0.0000, 0.0000, 0.9472, 0.0000]]])\n",
      "tensor([[[0.1790, 0.7364, 0.0000, 0.0000, 0.8842, 0.8169],\n",
      "         [0.1822, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.9729, 0.6414, 0.0000, 0.7861],\n",
      "         [0.0000, 0.6249, 0.0000, 0.9544, 0.0000, 0.8469],\n",
      "         [0.2706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.7421, 0.8574, 0.0000, 0.0000, 0.9472, 0.6615]]])\n",
      "tensor([[[0.0000, 0.7364, 0.0000, 0.0000, 0.8842, 0.0000],\n",
      "         [0.0000, 0.0000, 0.5224, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.9729, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6249, 0.0000, 0.0000, 0.8521, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4326, 0.0000, 0.0000],\n",
      "         [0.0000, 0.8574, 0.0000, 0.0000, 0.9472, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "# 二维反池化\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "tensor2d = torch.rand(1,6,6)\n",
    "print(tensor2d)\n",
    "\n",
    "# 最大反池化\n",
    "mp2d1 = nn.MaxPool2d(2, return_indices=True)\n",
    "output1, idx1 = mp2d1(tensor2d)\n",
    "ump2d1 = nn.MaxUnpool2d(2)\n",
    "output1 = ump2d1(output1,idx1)\n",
    "print(output1)\n",
    "\n",
    "# stride = 4\n",
    "mp2d2 = nn.MaxPool2d(2, stride=4, return_indices=True)\n",
    "output2, idx2 = mp2d2(tensor2d)\n",
    "ump2d2 = nn.MaxUnpool2d(2, stride=4)\n",
    "output2 = ump2d2(output2,idx2)\n",
    "print(output2)\n",
    "\n",
    "# padding = 1\n",
    "mp2d3 = nn.MaxPool2d(2, padding=1, return_indices=True)\n",
    "output3, idx3 = mp2d3(tensor2d)\n",
    "ump2d3 = nn.MaxUnpool2d(2, padding=1)\n",
    "output3 = ump2d3(output3,idx3)\n",
    "print(output3)\n",
    "\n",
    "# dilation = 1\n",
    "mp2d4 = nn.MaxPool2d(2, dilation=1, return_indices=True)\n",
    "output4, idx4 = mp2d4(tensor2d)\n",
    "ump2d4 = nn.MaxUnpool2d(2)\n",
    "output4 = ump2d4(output4,idx4)\n",
    "print(output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6289, 0.4205, 0.3737, 0.8886, 0.7913, 0.7375],\n",
      "         [0.6773, 0.2625, 0.6457, 0.1200, 0.3904, 0.0100],\n",
      "         [0.8974, 0.5871, 0.8100, 0.1675, 0.9007, 0.3236],\n",
      "         [0.8374, 0.2658, 0.1207, 0.5430, 0.3983, 0.5413],\n",
      "         [0.0316, 0.7297, 0.6655, 0.0236, 0.3069, 0.0482],\n",
      "         [0.8430, 0.2014, 0.6834, 0.3358, 0.4929, 0.3192]]])\n",
      "tensor([[[0.4973, 0.5070, 0.4823],\n",
      "         [0.6469, 0.4103, 0.5410],\n",
      "         [0.4514, 0.4271, 0.2918]]])\n",
      "tensor([[[0.4973, 0.4823],\n",
      "         [0.4514, 0.2918]]])\n",
      "tensor([[[0.1572, 0.1985, 0.4200, 0.1844],\n",
      "         [0.3937, 0.5763, 0.3946, 0.0834],\n",
      "         [0.2172, 0.4454, 0.3179, 0.1474],\n",
      "         [0.2108, 0.2212, 0.2072, 0.0798]]])\n"
     ]
    }
   ],
   "source": [
    "# 二维池化\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "tensor2d = torch.rand(1,6,6)\n",
    "print(tensor2d)\n",
    "\n",
    "# 平均池化\n",
    "ap2d1 = nn.AvgPool2d(2)\n",
    "output1 = ap2d1(tensor2d)\n",
    "print(output1)\n",
    "\n",
    "# stride = 4\n",
    "ap2d2 = nn.AvgPool2d(2, stride=4)\n",
    "output2 = ap2d2(tensor2d)\n",
    "print(output2)\n",
    "\n",
    "# padding = 1\n",
    "ap2d3 = nn.AvgPool2d(2, padding=1)\n",
    "output3 = ap2d3(tensor2d)\n",
    "print(output3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5961, 0.9451, 0.8869, 0.2692, 0.9652, 0.4953],\n",
      "          [0.4676, 0.0631, 0.0470, 0.2780, 0.4190, 0.4488],\n",
      "          [0.8041, 0.8174, 0.3911, 0.5169, 0.8580, 0.2478],\n",
      "          [0.9331, 0.7681, 0.2634, 0.5710, 0.5103, 0.0162],\n",
      "          [0.6469, 0.5795, 0.7397, 0.7567, 0.7690, 0.4016],\n",
      "          [0.4057, 0.1256, 0.2617, 0.6736, 0.1335, 0.0372]],\n",
      "\n",
      "         [[0.5670, 0.5199, 0.6359, 0.9407, 0.8284, 0.5327],\n",
      "          [0.3377, 0.3748, 0.9517, 0.7216, 0.9014, 0.2139],\n",
      "          [0.0212, 0.7039, 0.1293, 0.4358, 0.4387, 0.8799],\n",
      "          [0.7662, 0.5265, 0.7349, 0.4681, 0.5534, 0.7917],\n",
      "          [0.0682, 0.4208, 0.0963, 0.3161, 0.1570, 0.3185],\n",
      "          [0.3899, 0.0156, 0.7899, 0.7751, 0.8308, 0.7722]],\n",
      "\n",
      "         [[0.7824, 0.8408, 0.5932, 0.6729, 0.8129, 0.8495],\n",
      "          [0.0479, 0.9668, 0.9312, 0.7735, 0.1591, 0.4150],\n",
      "          [0.6206, 0.7304, 0.5090, 0.3260, 0.3657, 0.6144],\n",
      "          [0.6513, 0.6307, 0.2725, 0.0272, 0.3273, 0.1834],\n",
      "          [0.7289, 0.6836, 0.5535, 0.3888, 0.6036, 0.4147],\n",
      "          [0.1316, 0.1411, 0.8370, 0.4125, 0.3994, 0.0208]],\n",
      "\n",
      "         [[0.7385, 0.2948, 0.0576, 0.3878, 0.9967, 0.0303],\n",
      "          [0.1465, 0.9733, 0.8205, 0.2178, 0.8879, 0.8270],\n",
      "          [0.8320, 0.3388, 0.8442, 0.6175, 0.7885, 0.0699],\n",
      "          [0.7881, 0.9644, 0.8874, 0.4750, 0.2069, 0.8855],\n",
      "          [0.2581, 0.7366, 0.3772, 0.3621, 0.8265, 0.3622],\n",
      "          [0.8509, 0.2528, 0.1966, 0.2868, 0.4584, 0.5409]],\n",
      "\n",
      "         [[0.9591, 0.5050, 0.0013, 0.9454, 0.8425, 0.0379],\n",
      "          [0.8976, 0.0994, 0.3670, 0.9145, 0.0352, 0.7476],\n",
      "          [0.9039, 0.3591, 0.6230, 0.5032, 0.1255, 0.9684],\n",
      "          [0.6144, 0.0206, 0.8849, 0.2164, 0.3494, 0.2187],\n",
      "          [0.2342, 0.9536, 0.8939, 0.3826, 0.5447, 0.0619],\n",
      "          [0.0783, 0.0903, 0.2355, 0.0614, 0.8278, 0.9453]],\n",
      "\n",
      "         [[0.7823, 0.3113, 0.7042, 0.8338, 0.2957, 0.1526],\n",
      "          [0.5925, 0.1517, 0.7627, 0.9939, 0.8691, 0.7118],\n",
      "          [0.7168, 0.6126, 0.9761, 0.1095, 0.9561, 0.5827],\n",
      "          [0.2564, 0.4847, 0.0415, 0.6839, 0.0060, 0.4901],\n",
      "          [0.5141, 0.1569, 0.5158, 0.0602, 0.4142, 0.9802],\n",
      "          [0.6150, 0.0459, 0.3741, 0.5678, 0.5987, 0.1420]]]])\n",
      "tensor([[[[0.9451, 0.9517, 0.9652],\n",
      "          [0.9331, 0.7349, 0.8799],\n",
      "          [0.6469, 0.7899, 0.8308]],\n",
      "\n",
      "         [[0.9733, 0.9312, 0.9967],\n",
      "          [0.9644, 0.8874, 0.8855],\n",
      "          [0.8509, 0.8370, 0.8265]],\n",
      "\n",
      "         [[0.9591, 0.9939, 0.8691],\n",
      "          [0.9039, 0.9761, 0.9684],\n",
      "          [0.9536, 0.8939, 0.9802]]]])\n",
      "tensor([[[[0.9451, 0.9652],\n",
      "          [0.6469, 0.8308]],\n",
      "\n",
      "         [[0.9591, 0.8691],\n",
      "          [0.9536, 0.9802]]]])\n",
      "tensor([[[[0.5961, 0.9451, 0.9652, 0.4953],\n",
      "          [0.8041, 0.8174, 0.8580, 0.4488],\n",
      "          [0.9331, 0.7681, 0.7690, 0.4016],\n",
      "          [0.4057, 0.2617, 0.6736, 0.0372]],\n",
      "\n",
      "         [[0.7824, 0.8408, 0.9407, 0.8495],\n",
      "          [0.6206, 0.9668, 0.9014, 0.8799],\n",
      "          [0.7662, 0.7349, 0.6036, 0.7917],\n",
      "          [0.3899, 0.8370, 0.8308, 0.7722]],\n",
      "\n",
      "         [[0.9591, 0.5050, 0.9967, 0.0379],\n",
      "          [0.9039, 0.9733, 0.9145, 0.9684],\n",
      "          [0.7881, 0.9644, 0.8265, 0.8855],\n",
      "          [0.8509, 0.2528, 0.8278, 0.9453]],\n",
      "\n",
      "         [[0.7823, 0.7042, 0.8338, 0.1526],\n",
      "          [0.7168, 0.9761, 0.9939, 0.7118],\n",
      "          [0.5141, 0.5158, 0.6839, 0.9802],\n",
      "          [0.6150, 0.3741, 0.5987, 0.1420]]]])\n",
      "tensor([[[[0.9451, 0.9517, 0.9652],\n",
      "          [0.9331, 0.7349, 0.8799],\n",
      "          [0.6469, 0.7899, 0.8308]],\n",
      "\n",
      "         [[0.9733, 0.9312, 0.9967],\n",
      "          [0.9644, 0.8874, 0.8855],\n",
      "          [0.8509, 0.8370, 0.8265]],\n",
      "\n",
      "         [[0.9591, 0.9939, 0.8691],\n",
      "          [0.9039, 0.9761, 0.9684],\n",
      "          [0.9536, 0.8939, 0.9802]]]])\n"
     ]
    }
   ],
   "source": [
    "# 三维池化\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "tensor3d = torch.rand(1,6,6,6)\n",
    "print(tensor3d)\n",
    "\n",
    "# 最大池化\n",
    "mp3d1 = nn.MaxPool3d(2)\n",
    "output1 = mp3d1(tensor3d)\n",
    "print(output1)\n",
    "\n",
    "# stride = 4\n",
    "mp3d2 = nn.MaxPool3d(2, stride=4)\n",
    "output2 = mp3d2(tensor3d)\n",
    "print(output2)\n",
    "\n",
    "# padding = 1\n",
    "mp3d3 = nn.MaxPool3d(2, padding=1)\n",
    "output3 = mp3d3(tensor3d)\n",
    "print(output3)\n",
    "\n",
    "# dilation = 1\n",
    "mp3d4 = nn.MaxPool3d(2, dilation=1)\n",
    "output4 = mp3d4(tensor3d)\n",
    "print(output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.8012, 0.6889, 0.8032, 0.1090, 0.2765, 0.9103],\n",
      "          [0.6522, 0.0688, 0.3431, 0.3723, 0.9794, 0.2167],\n",
      "          [0.4596, 0.5113, 0.9752, 0.5203, 0.1399, 0.2547],\n",
      "          [0.8382, 0.3423, 0.7142, 0.1108, 0.6540, 0.3123],\n",
      "          [0.8574, 0.0060, 0.2485, 0.8537, 0.0012, 0.1747],\n",
      "          [0.5621, 0.5604, 0.8530, 0.9426, 0.5580, 0.6675]],\n",
      "\n",
      "         [[0.8434, 0.4520, 0.2518, 0.2118, 0.3501, 0.4994],\n",
      "          [0.7259, 0.5684, 0.6545, 0.0853, 0.4659, 0.3236],\n",
      "          [0.7097, 0.6118, 0.0998, 0.0082, 0.0422, 0.4702],\n",
      "          [0.5869, 0.9557, 0.3768, 0.1387, 0.9773, 0.2596],\n",
      "          [0.5467, 0.8999, 0.7528, 0.8821, 0.7892, 0.1083],\n",
      "          [0.9742, 0.2551, 0.3595, 0.5494, 0.4295, 0.1002]],\n",
      "\n",
      "         [[0.7151, 0.2850, 0.9933, 0.5600, 0.6571, 0.0365],\n",
      "          [0.2084, 0.4711, 0.5418, 0.2343, 0.5707, 0.4966],\n",
      "          [0.6599, 0.0156, 0.7455, 0.7129, 0.1798, 0.3048],\n",
      "          [0.8497, 0.9379, 0.1565, 0.4446, 0.9254, 0.9209],\n",
      "          [0.7207, 0.0832, 0.6292, 0.1624, 0.7822, 0.2460],\n",
      "          [0.0530, 0.1992, 0.9147, 0.2478, 0.7162, 0.1751]],\n",
      "\n",
      "         [[0.4744, 0.6487, 0.4646, 0.0484, 0.8099, 0.4622],\n",
      "          [0.7136, 0.6794, 0.5503, 0.1061, 0.9375, 0.3313],\n",
      "          [0.2191, 0.4296, 0.1313, 0.9323, 0.7207, 0.1315],\n",
      "          [0.8403, 0.1537, 0.9119, 0.6633, 0.3783, 0.3352],\n",
      "          [0.1334, 0.6426, 0.9980, 0.3706, 0.8684, 0.0253],\n",
      "          [0.7993, 0.6488, 0.6530, 0.3369, 0.0525, 0.8775]],\n",
      "\n",
      "         [[0.7065, 0.1871, 0.4871, 0.8724, 0.2524, 0.5960],\n",
      "          [0.7107, 0.6623, 0.3446, 0.7336, 0.2295, 0.1887],\n",
      "          [0.5091, 0.8264, 0.6335, 0.8399, 0.3386, 0.5777],\n",
      "          [0.9520, 0.0271, 0.6818, 0.5764, 0.1604, 0.8424],\n",
      "          [0.3472, 0.9327, 0.5450, 0.9091, 0.9309, 0.6711],\n",
      "          [0.8055, 0.7257, 0.3911, 0.3211, 0.5080, 0.6052]],\n",
      "\n",
      "         [[0.0828, 0.7402, 0.8706, 0.0045, 0.0508, 0.6425],\n",
      "          [0.6572, 0.4018, 0.7761, 0.0997, 0.9432, 0.1551],\n",
      "          [0.1187, 0.0895, 0.3458, 0.1082, 0.8550, 0.5545],\n",
      "          [0.8593, 0.6221, 0.3512, 0.6318, 0.2892, 0.5343],\n",
      "          [0.6960, 0.2081, 0.8879, 0.6702, 0.6472, 0.1129],\n",
      "          [0.2817, 0.9469, 0.7419, 0.0083, 0.3726, 0.0231]]]])\n",
      "tensor([[[[0.0000, 0.0000, 0.8032, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.9794, 0.0000],\n",
      "          [0.0000, 0.0000, 0.9752, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.9426, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.8434, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9557, 0.0000, 0.0000, 0.9773, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.7892, 0.0000],\n",
      "          [0.9742, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.7151, 0.0000, 0.9933, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9379, 0.0000, 0.0000, 0.9254, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.9375, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.9323, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.9980, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7993, 0.0000, 0.0000, 0.0000, 0.0000, 0.8775]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.8724, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.8399, 0.0000, 0.0000],\n",
      "          [0.9520, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.9091, 0.9309, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.7402, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.9432, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.8550, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9469, 0.0000, 0.0000, 0.0000, 0.0000]]]])\n",
      "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.9794, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.8434, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.7892, 0.0000],\n",
      "          [0.9742, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.9309, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.7402, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.9432, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9469, 0.0000, 0.0000, 0.0000, 0.0000]]]])\n",
      "tensor([[[[0.8012, 0.0000, 0.8032, 0.0000, 0.2765, 0.9103],\n",
      "          [0.6522, 0.0000, 0.0000, 0.0000, 0.9794, 0.0000],\n",
      "          [0.0000, 0.0000, 0.9752, 0.0000, 0.0000, 0.2547],\n",
      "          [0.0000, 0.0000, 0.7142, 0.0000, 0.0000, 0.3123],\n",
      "          [0.8574, 0.0000, 0.0000, 0.8537, 0.0000, 0.0000],\n",
      "          [0.5621, 0.0000, 0.8530, 0.9426, 0.0000, 0.6675]],\n",
      "\n",
      "         [[0.8434, 0.0000, 0.0000, 0.0000, 0.0000, 0.4994],\n",
      "          [0.7259, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9557, 0.0000, 0.0000, 0.9773, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.9742, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.9933, 0.0000, 0.6571, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4966],\n",
      "          [0.0000, 0.0000, 0.7455, 0.7129, 0.0000, 0.0000],\n",
      "          [0.8497, 0.0000, 0.0000, 0.0000, 0.0000, 0.9209],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.9147, 0.0000, 0.7162, 0.1751]],\n",
      "\n",
      "         [[0.0000, 0.6487, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7136, 0.0000, 0.0000, 0.0000, 0.9375, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.9980, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8775]],\n",
      "\n",
      "         [[0.7065, 0.0000, 0.0000, 0.8724, 0.0000, 0.5960],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.8264, 0.0000, 0.0000, 0.0000, 0.5777],\n",
      "          [0.9520, 0.0000, 0.0000, 0.0000, 0.0000, 0.8424],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.9309, 0.0000],\n",
      "          [0.8055, 0.7257, 0.0000, 0.0000, 0.5080, 0.0000]],\n",
      "\n",
      "         [[0.0828, 0.0000, 0.8706, 0.0000, 0.0508, 0.6425],\n",
      "          [0.6572, 0.0000, 0.7761, 0.0000, 0.9432, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5545],\n",
      "          [0.8593, 0.0000, 0.0000, 0.0000, 0.0000, 0.5343],\n",
      "          [0.0000, 0.0000, 0.8879, 0.6702, 0.0000, 0.0000],\n",
      "          [0.2817, 0.9469, 0.0000, 0.0000, 0.3726, 0.0231]]]])\n",
      "tensor([[[[0.0000, 0.0000, 0.8032, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.9794, 0.0000],\n",
      "          [0.0000, 0.0000, 0.9752, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.9426, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.8434, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9557, 0.0000, 0.0000, 0.9773, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.7892, 0.0000],\n",
      "          [0.9742, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.7151, 0.0000, 0.9933, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9379, 0.0000, 0.0000, 0.9254, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.9375, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.9323, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.9980, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7993, 0.0000, 0.0000, 0.0000, 0.0000, 0.8775]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.8724, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.8399, 0.0000, 0.0000],\n",
      "          [0.9520, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.9091, 0.9309, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.7402, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.9432, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.8550, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9469, 0.0000, 0.0000, 0.0000, 0.0000]]]])\n"
     ]
    }
   ],
   "source": [
    "# 三维反池化\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "tensor3d = torch.rand(1,6,6,6)\n",
    "print(tensor3d)\n",
    "\n",
    "# 最大反池化\n",
    "mp3d1 = nn.MaxPool3d(2, return_indices=True)\n",
    "output1, idx1 = mp3d1(tensor3d)\n",
    "ump3d1 = nn.MaxUnpool3d(2)\n",
    "output1 = ump3d1(output1,idx1)\n",
    "print(output1)\n",
    "\n",
    "# stride = 4\n",
    "mp3d2 = nn.MaxPool3d(2, stride=4, return_indices=True)\n",
    "output2, idx2 = mp3d2(tensor3d)\n",
    "ump3d2 = nn.MaxUnpool3d(2, stride=4)\n",
    "output2 = ump3d2(output2,idx2)\n",
    "print(output2)\n",
    "\n",
    "# padding = 1\n",
    "mp3d3 = nn.MaxPool3d(2, padding=1, return_indices=True)\n",
    "output3, idx3 = mp3d3(tensor3d)\n",
    "ump3d3 = nn.MaxUnpool3d(2, padding=1)\n",
    "output3 = ump3d3(output3,idx3)\n",
    "print(output3)\n",
    "\n",
    "# dilation = 1\n",
    "mp3d4 = nn.MaxPool3d(2, dilation=1, return_indices=True)\n",
    "output4, idx4 = mp3d4(tensor3d)\n",
    "ump3d4 = nn.MaxUnpool3d(2)\n",
    "output4 = ump3d4(output4,idx4)\n",
    "print(output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.8034, 0.1727, 0.7565, 0.8877, 0.9927, 0.2689],\n",
      "          [0.5552, 0.1987, 0.4931, 0.2873, 0.1225, 0.4354],\n",
      "          [0.6525, 0.8345, 0.9658, 0.1096, 0.5848, 0.3912],\n",
      "          [0.3372, 0.7469, 0.4027, 0.0920, 0.5781, 0.3467],\n",
      "          [0.4712, 0.3757, 0.6502, 0.7183, 0.4207, 0.6976],\n",
      "          [0.0853, 0.8718, 0.9881, 0.3815, 0.2203, 0.6706]],\n",
      "\n",
      "         [[0.9323, 0.8169, 0.9648, 0.4480, 0.9665, 0.0423],\n",
      "          [0.3330, 0.1700, 0.8740, 0.7037, 0.6270, 0.4229],\n",
      "          [0.8915, 0.2363, 0.7087, 0.1624, 0.4827, 0.4093],\n",
      "          [0.3720, 0.2374, 0.9452, 0.4332, 0.7222, 0.8694],\n",
      "          [0.8460, 0.3238, 0.9430, 0.9330, 0.8583, 0.8391],\n",
      "          [0.1374, 0.0854, 0.4257, 0.3800, 0.9021, 0.7699]],\n",
      "\n",
      "         [[0.6487, 0.5266, 0.3948, 0.8764, 0.2897, 0.8394],\n",
      "          [0.1977, 0.1266, 0.6012, 0.9254, 0.2941, 0.3470],\n",
      "          [0.3794, 0.9109, 0.1270, 0.4958, 0.4479, 0.1641],\n",
      "          [0.9613, 0.1500, 0.1146, 0.9491, 0.6353, 0.8202],\n",
      "          [0.1273, 0.4614, 0.3192, 0.0309, 0.2157, 0.8158],\n",
      "          [0.5908, 0.7169, 0.4127, 0.4972, 0.6345, 0.9451]],\n",
      "\n",
      "         [[0.1683, 0.8813, 0.4951, 0.7765, 0.4515, 0.4891],\n",
      "          [0.0315, 0.5899, 0.9708, 0.4531, 0.6629, 0.5196],\n",
      "          [0.7330, 0.3585, 0.1459, 0.1846, 0.0187, 0.8808],\n",
      "          [0.3835, 0.6177, 0.7044, 0.0060, 0.3642, 0.6706],\n",
      "          [0.4415, 0.2475, 0.8152, 0.5251, 0.8525, 0.5970],\n",
      "          [0.5507, 0.0407, 0.5593, 0.0935, 0.0073, 0.1907]],\n",
      "\n",
      "         [[0.3914, 0.2471, 0.4188, 0.9219, 0.9552, 0.1542],\n",
      "          [0.2547, 0.3210, 0.9151, 0.3322, 0.2148, 0.6239],\n",
      "          [0.8264, 0.7955, 0.7141, 0.2970, 0.4493, 0.3197],\n",
      "          [0.7763, 0.4482, 0.3283, 0.9003, 0.7014, 0.8860],\n",
      "          [0.0297, 0.3600, 0.7449, 0.2745, 0.7632, 0.8825],\n",
      "          [0.8894, 0.5767, 0.3450, 0.3835, 0.9228, 0.3820]],\n",
      "\n",
      "         [[0.1495, 0.4677, 0.7476, 0.6456, 0.7766, 0.0794],\n",
      "          [0.8056, 0.9821, 0.1940, 0.5372, 0.6559, 0.2249],\n",
      "          [0.7003, 0.4609, 0.2386, 0.8141, 0.6738, 0.0227],\n",
      "          [0.1867, 0.9979, 0.7909, 0.1140, 0.4769, 0.6288],\n",
      "          [0.0705, 0.0030, 0.2978, 0.4799, 0.3785, 0.4514],\n",
      "          [0.0535, 0.7640, 0.3802, 0.4446, 0.3101, 0.5703]]]])\n",
      "tensor([[[[0.4978, 0.6769, 0.4848],\n",
      "          [0.5385, 0.4775, 0.5480],\n",
      "          [0.3996, 0.6775, 0.6723]],\n",
      "\n",
      "         [[0.3963, 0.6867, 0.4867],\n",
      "          [0.5618, 0.3409, 0.5002],\n",
      "          [0.3971, 0.4066, 0.5323]],\n",
      "\n",
      "         [[0.4524, 0.5890, 0.4606],\n",
      "          [0.6490, 0.5246, 0.5198],\n",
      "          [0.3433, 0.4188, 0.5826]]]])\n",
      "tensor([[[[0.4978, 0.4848],\n",
      "          [0.3996, 0.6723]],\n",
      "\n",
      "         [[0.4524, 0.4606],\n",
      "          [0.3433, 0.5826]]]])\n",
      "tensor([[[[0.1004, 0.1162, 0.2350, 0.0336],\n",
      "          [0.1510, 0.3115, 0.1380, 0.1033],\n",
      "          [0.1010, 0.2719, 0.2261, 0.1305],\n",
      "          [0.0107, 0.2325, 0.0752, 0.0838]],\n",
      "\n",
      "         [[0.1976, 0.3379, 0.3226, 0.1102],\n",
      "          [0.2252, 0.4693, 0.5174, 0.1679],\n",
      "          [0.2883, 0.4368, 0.5972, 0.4181],\n",
      "          [0.0910, 0.2051, 0.3017, 0.2144]],\n",
      "\n",
      "         [[0.0700, 0.2553, 0.3881, 0.0804],\n",
      "          [0.2307, 0.6013, 0.3266, 0.2930],\n",
      "          [0.2039, 0.5333, 0.5484, 0.3795],\n",
      "          [0.1800, 0.1902, 0.1759, 0.0716]],\n",
      "\n",
      "         [[0.0187, 0.1519, 0.1778, 0.0099],\n",
      "          [0.1882, 0.2344, 0.3351, 0.0310],\n",
      "          [0.0321, 0.2612, 0.1812, 0.1350],\n",
      "          [0.0067, 0.1430, 0.0943, 0.0713]]]])\n"
     ]
    }
   ],
   "source": [
    "# 三维池化\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "tensor3d = torch.rand(1,6,6,6)\n",
    "print(tensor3d)\n",
    "\n",
    "# 平均池化\n",
    "ap3d1 = nn.AvgPool3d(2)\n",
    "output1 = ap3d1(tensor3d)\n",
    "print(output1)\n",
    "\n",
    "# stride = 4\n",
    "ap3d2 = nn.AvgPool3d(2, stride=4)\n",
    "output2 = ap3d2(tensor3d)\n",
    "print(output2)\n",
    "\n",
    "# padding = 1\n",
    "ap3d3 = nn.AvgPool3d(2, padding=1)\n",
    "output3 = ap3d3(tensor3d)\n",
    "print(output3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### 特征工程与表示学习\n",
    "\n",
    "#### 特征\n",
    "\n",
    "特征就是原始数据某个方面的数值表示。在机器学习流程中，特征是数据和模型之间的纽带。而特征工程与表示学习则是从原始数据中提取特征并将其转换为适合机器学习模型的格式的方法。\n",
    "\n",
    "那么如何识别特征呢？对于大脑来说，是根据眼睛观察到的事物的大小形状等识别出来的。但是对于计算机而言，这些都是数值罢了，因此需要一些方法来识别。\n",
    "\n",
    "机器学习一般有两种思路来提升原始数据的表达：\n",
    "1. 特征学习(feature learning)，又叫表示学习(representation learning)或者表征学习，一般指模型自动从数据中抽取特征或者表示的方法，是模型自动学习的过程；\n",
    "2. 特征工程(feature engineering)，主要指对于数据的人为处理提取，得到我们认为的适合后续模型使用的样式，是人工提取的工程 （狭义的特征工程指的是“洗数据”：处理缺失值，特征选择，维度压缩等各种预处理手段，但从更广义的角度看，这些处理是为了使得数据有更好的表达以便后续应用）\n",
    "\n",
    "![feature_learning](./img/feature_learning.png)\n",
    "\n",
    "传统的机器学习方法主要依赖人工特征处理与提取，而深度学习则依赖模型自身去学习数据的表示（自动抽取有效特征）。\n",
    "\n",
    "#### 表示学习\n",
    "\n",
    "输入数据经过层层网络，依次被抽取出了低级特征（low level features）比如边缘色度，中级特征（middle level features）比如纹理角点，和高级特征比如图形，然后把高度抽象化的高级特征交给最后的分类器层进行预测，从而得到分类结果。深度网络最后一层一般就是个线性分类器，比如softmax线性回归分类，深度神经网络的其他部分可以看做是为最后一层的分类器提供表征。\n",
    "\n",
    "通过层层网络抽取高度抽象化的特征，最终目的是为了帮助分类器做出良好的预测：最开始输入网络的特征可能是线性不可分的，但是到最后隐藏层时变得线性可分了。如果只看分类器层的话深度学习和其他机器学习没有太大差别，正是前面层层网络良好有效的抽取特征的能力使得深度学习脱颖而出。\n",
    "\n",
    "#### 卷积和特征提取\n",
    "\n",
    "我们可以通过卷积的方式来提取图像的特征\n",
    "\n",
    "![feature_conv1](./img/feature_conv1.png)\n",
    "\n",
    "我们可以利用像素和邻域像素之间的差异，设计卷积核来提取图像的局部特征。经过不同卷积核的卷积运算后，可以起到不同的作用，比如高斯平滑卷积核可以被看做每个像素被其邻居像素平均（边缘模糊），见上图；而边缘检测的卷积核，就是将每个像素和其邻域像素做差值，见下图。\n",
    "\n",
    "![feature_conv2](./img/feature_conv2.png)\n",
    "\n",
    "再比如识别一个曲线，可以按照曲线的形状走向设计卷积核的形状，在遇到类似图像的时候，卷积运算后的数值会很大（对应位置像素值相乘后相加），反之很小，即可识别想要的形状。以上也是卷积核又称为滤波器或者模板的原因。\n",
    "\n",
    "传统的图像处理，就是人工设计好了不同的卷积核（滤波器）去提取不同特征，常见的滤波器：高通、低通、高斯模糊、SOBEL 查找边缘 … 是白盒。但非常依赖经验，提取规则只适用特定数据和问题，对于某些任务，特征并不单一和具体，很难设计适合的滤波器。比如计算机视觉领域的目标检测：想要设计一个卷积核检测眼睛位置，但是不同的人，眼睛大小状态是不同的，如果卷积核太过具体化，卷积核代表一个睁开的眼睛特征，给出一张图片的眼睛是闭合的，就很大可能检测不出来。对于这种问题，我们如何设计卷积核呢，即，如何确定卷积核的值呢？\n",
    "\n",
    "深度学习可以自动寻找合适的卷积核来完成特征提取（卷积核的固定值被替换为参数来求解），得到的“滤波器”是黑盒，神经网络不需要理解数字代表的业务含义，它只需要尝试找到最合适的卷积核等各种参数，使得在给定数据上loss最小就可以了 （求解卷积核参数的过程涉及到损失函数，梯度下降，反向传播等：使得最终的卷积核，通过它提取出来的特征，能够使预测得到的结果和真值尽可能接近）。\n",
    "\n",
    "#### 本节参考\n",
    "\n",
    "[表示学习（特征学习）](https://blog.csdn.net/weixin_43026262/article/details/103980616)\n",
    "\n",
    "[那么......什么是卷积？ - 8:32](https://www.bilibili.com/video/BV1Vd4y1e7pj/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### [Non-linear Activations 非线性激活函数](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n",
    "\n",
    "Non-linear Activations 为pytorch提供用于神经网络中相关的非线性激活函数。\n",
    "\n",
    "|函数|简介|\n",
    "|---|---|\n",
    "|**nn.ELU**|Exponential Linear Unit (ELU) function 指数线性单元|\n",
    "|nn.Hardshrink|Hard Shrinkage (Hardshrink) function|\n",
    "|nn.Hardsigmoid|Hardsigmoid function|\n",
    "|nn.Hardtanh|HardTanh function|\n",
    "|nn.Hardswish|Hardswish function|\n",
    "|**nn.LeakyReLU**|LeakyReLU function|\n",
    "|nn.LogSigmoid|Logsigmoid function|\n",
    "|nn.MultiheadAttention|多注意头原理|\n",
    "|nn.PReLU|PReLU function|\n",
    "|**nn.ReLU**|rectified linear unit function 修正线性单元|\n",
    "|nn.ReLU6|ReLU6 function|\n",
    "|nn.RReLU|randomized leaky rectified linear unit function|\n",
    "|nn.SELU|SELU function|\n",
    "|nn.CELU|CELU function|\n",
    "|nn.GELU|Gaussian Error Linear Units function|\n",
    "|**nn.Sigmoid**|Sigmoid function|\n",
    "|nn.SiLU|Sigmoid Linear Unit (SiLU) function|\n",
    "|nn.Mish|Mish function|\n",
    "|nn.Softplus|Softplus function|\n",
    "|nn.Softshrink|soft shrinkage function|\n",
    "|nn.Softsign|Softsign function|\n",
    "|**nn.Tanh**|Hyperbolic Tangent (Tanh) function|\n",
    "|nn.Tanhshrink|Tanhshrink function|\n",
    "|nn.Threshold|对输入进Threshold的Tensor进行阈值操作|\n",
    "|nn.GLU|gated linear unit function|\n",
    "|---|---|\n",
    "|nn.Softmin|Softmin function|\n",
    "|**nn.Softmax**|Softmax function|\n",
    "|nn.Softmax2d|Applies SoftMax over features to each spatial location|\n",
    "|nn.LogSoftmax|log(Softmax(x))|\n",
    "|nn.AdaptiveLogSoftmaxWithLoss|Efficient softmax approximation|\n",
    "\n",
    "其中常见的激活函数有Sigmoid, Tanh, ReLU, LeakyReLU, ELU, Softmax等。\n",
    "\n",
    "激活函数（Activation Function）是一种添加到人工神经网络中的函数，旨在帮助网络学习数据中的复杂模式。类似于人类大脑中基于神经元的模型，激活函数最终决定了要发射给下一个神经元的内容。\n",
    "\n",
    "关于神经网络中的激活函数的作用，通常都是这样解释：不使用激活函数的话，神经网络的每层都只是做线性变换，多层输入叠加后也还是线性变换。因为线性模型的表达能力通常不够，所以这时候就体现了激活函数的作用了，激活函数可以引入非线性因素。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### 梯度消失和梯度爆炸\n",
    "\n",
    "层数比较多的神经网络模型在训练的时候会出现梯度消失(gradient vanishing problem)和梯度爆炸(gradient exploding problem)问题。梯度消失问题和梯度爆炸问题一般会随着网络层数的增加变得越来越明显。\n",
    "\n",
    "对一个三个隐藏层的神经网络来说：\n",
    "\n",
    "- 梯度消失发生时，靠近输出层的隐藏层3梯度相对正常，但是靠近输入层的隐藏层1梯度几乎为0，导致靠近输入层的隐藏层权值几乎不变，仍接近于初始化的权值。这就导致这一层相当于只是一个映射层，对所有的输入做了一个函数映射，这时此深度神经网络的学习就等价于只有后几层的隐藏层网络在学习。\n",
    "- 梯度爆炸则是，靠近输入层的隐藏层1梯度非常大，导致每次训练的权值变化很大，训练无法收敛。\n",
    "\n",
    "##### 梯度消失和梯度爆炸的原因\n",
    "\n",
    "对于一个神经网络而言，更新各个神经元的参数的最常见的方法就是反向传播，而反向传播计算的各个神经元的梯度的规则是链式求导法则。因此对于一个每层输入输出关系$z_ i=σ(y_ i)=σ(w_ i x_ i+b_ i)$，以及以下结构的神经网络而言。\n",
    "\n",
    "$\n",
    "\n",
    "它的梯度为\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### Sigmoid 函数\n",
    "\n",
    "Sigmoid函数的方程为$σ=\\frac{1}{1+e^{-x}}$，求导公式为$σ'=σ(1-σ)$。\n",
    "\n",
    "因此其取值范围为(0, 1)，梯度取值范围为(0, 0.25)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
